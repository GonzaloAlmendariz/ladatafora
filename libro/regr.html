<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Regresión – R para el análisis de datos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./glosariofunciones.html" rel="next">
<link href="./comp.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regr.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Regresión</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">R para el análisis de datos</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Agradecimientos</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Estructura del libro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Fundamentos de la Estadística</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentosR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Fundamentos de R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./integración.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Integración</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./statdesc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Estadística descriptiva</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probabilidad</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Estadística inferencial</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./comp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Comparando grupos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regr.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Regresión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glosariofunciones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Glosario de funciones y operaciones útiles en R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./solucionario.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Solucionario</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bilbiografía</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#regresión-lineal-simple" id="toc-regresión-lineal-simple" class="nav-link active" data-scroll-target="#regresión-lineal-simple"><span class="header-section-number">8.1</span> Regresión lineal simple</a>
  <ul class="collapse">
  <li><a href="#ecuación-de-regresión-lineal" id="toc-ecuación-de-regresión-lineal" class="nav-link" data-scroll-target="#ecuación-de-regresión-lineal"><span class="header-section-number">8.1.1</span> Ecuación de regresión lineal</a></li>
  <li><a href="#mínimos-cuadrados-ordinarios-ols" id="toc-mínimos-cuadrados-ordinarios-ols" class="nav-link" data-scroll-target="#mínimos-cuadrados-ordinarios-ols"><span class="header-section-number">8.1.2</span> Mínimos cuadrados ordinarios (OLS)</a></li>
  <li><a href="#desviación-estándar-condicional" id="toc-desviación-estándar-condicional" class="nav-link" data-scroll-target="#desviación-estándar-condicional"><span class="header-section-number">8.1.3</span> Desviación estándar condicional</a></li>
  <li><a href="#la-correlación-y-la-pendiente" id="toc-la-correlación-y-la-pendiente" class="nav-link" data-scroll-target="#la-correlación-y-la-pendiente"><span class="header-section-number">8.1.4</span> La correlación y la pendiente</a></li>
  <li><a href="#coeficiente-de-determinación" id="toc-coeficiente-de-determinación" class="nav-link" data-scroll-target="#coeficiente-de-determinación"><span class="header-section-number">8.1.5</span> Coeficiente de determinación</a></li>
  <li><a href="#resumen-del-modelo-en-r-con-summary" id="toc-resumen-del-modelo-en-r-con-summary" class="nav-link" data-scroll-target="#resumen-del-modelo-en-r-con-summary"><span class="header-section-number">8.1.6</span> Resumen del modelo en R con <code>summary()</code></a></li>
  </ul></li>
  <li><a href="#inferencia-de-coeficientes-para-el-modelo-lineal" id="toc-inferencia-de-coeficientes-para-el-modelo-lineal" class="nav-link" data-scroll-target="#inferencia-de-coeficientes-para-el-modelo-lineal"><span class="header-section-number">8.2</span> Inferencia de coeficientes para el modelo lineal</a>
  <ul class="collapse">
  <li><a href="#estimación-de-la-pendiente" id="toc-estimación-de-la-pendiente" class="nav-link" data-scroll-target="#estimación-de-la-pendiente"><span class="header-section-number">8.2.1</span> Estimación de la pendiente</a></li>
  <li><a href="#prueba-de-independencia-contraste-de-hipótesis-sobre-beta" id="toc-prueba-de-independencia-contraste-de-hipótesis-sobre-beta" class="nav-link" data-scroll-target="#prueba-de-independencia-contraste-de-hipótesis-sobre-beta"><span class="header-section-number">8.2.2</span> Prueba de independencia: contraste de hipótesis sobre <span class="math inline">\(\beta\)</span></a></li>
  <li><a href="#supuestos-y-calidad-de-ajuste" id="toc-supuestos-y-calidad-de-ajuste" class="nav-link" data-scroll-target="#supuestos-y-calidad-de-ajuste"><span class="header-section-number">8.2.3</span> Supuestos y calidad de ajuste</a></li>
  </ul></li>
  <li><a href="#regresión-múltiple" id="toc-regresión-múltiple" class="nav-link" data-scroll-target="#regresión-múltiple"><span class="header-section-number">8.3</span> Regresión múltiple</a>
  <ul class="collapse">
  <li><a href="#modelo-de-regresión-múltiple" id="toc-modelo-de-regresión-múltiple" class="nav-link" data-scroll-target="#modelo-de-regresión-múltiple"><span class="header-section-number">8.3.1</span> Modelo de regresión múltiple</a></li>
  <li><a href="#control-de-variables" id="toc-control-de-variables" class="nav-link" data-scroll-target="#control-de-variables"><span class="header-section-number">8.3.2</span> Control de variables</a></li>
  <li><a href="#evaluando-multicolinealidad" id="toc-evaluando-multicolinealidad" class="nav-link" data-scroll-target="#evaluando-multicolinealidad"><span class="header-section-number">8.3.3</span> Evaluando multicolinealidad</a></li>
  <li><a href="#r2-en-la-correlación-múltiple" id="toc-r2-en-la-correlación-múltiple" class="nav-link" data-scroll-target="#r2-en-la-correlación-múltiple"><span class="header-section-number">8.3.4</span> R2 en la correlación múltiple</a></li>
  <li><a href="#inferencia-de-coeficientes" id="toc-inferencia-de-coeficientes" class="nav-link" data-scroll-target="#inferencia-de-coeficientes"><span class="header-section-number">8.3.5</span> Inferencia de coeficientes</a></li>
  <li><a href="#modelos-múltiples-con-interacción" id="toc-modelos-múltiples-con-interacción" class="nav-link" data-scroll-target="#modelos-múltiples-con-interacción"><span class="header-section-number">8.3.6</span> Modelos múltiples con interacción</a></li>
  </ul></li>
  <li><a href="#un-vistazo-a-otros-modelos-de-regresión" id="toc-un-vistazo-a-otros-modelos-de-regresión" class="nav-link" data-scroll-target="#un-vistazo-a-otros-modelos-de-regresión"><span class="header-section-number">8.4</span> Un vistazo a otros modelos de regresión</a>
  <ul class="collapse">
  <li><a href="#más-allá-de-la-linealidad" id="toc-más-allá-de-la-linealidad" class="nav-link" data-scroll-target="#más-allá-de-la-linealidad"><span class="header-section-number">8.4.1</span> Más allá de la linealidad</a></li>
  <li><a href="#modelos-lineales-generalizados" id="toc-modelos-lineales-generalizados" class="nav-link" data-scroll-target="#modelos-lineales-generalizados"><span class="header-section-number">8.4.2</span> Modelos lineales generalizados</a></li>
  </ul></li>
  <li><a href="#resumen-del-capítulo" id="toc-resumen-del-capítulo" class="nav-link" data-scroll-target="#resumen-del-capítulo"><span class="header-section-number">8.5</span> Resumen del capítulo</a></li>
  <li><a href="#ejercicios" id="toc-ejercicios" class="nav-link" data-scroll-target="#ejercicios"><span class="header-section-number">8.6</span> Ejercicios</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Regresión</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>En los capítulos anteriores, vimos cómo realizar estimaciones y pruebas de significancia en variables tanto numéricas como categóricas. En este capítulo, nos enfocaremos en analizar la relación entre una variable respuesta numérica y una o más variables explicativas. Este tipo de análisis se conoce como <strong>análisis de regresión</strong>, uno de los métodos más utilizados en las ciencias sociales para interpretar y modelar situaciones de la realidad social.</p>
<section id="regresión-lineal-simple" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="regresión-lineal-simple"><span class="header-section-number">8.1</span> Regresión lineal simple</h2>
<p>¿Recuerdas nuestro ejemplo sobre la relación entre el PIB per cápita y la esperanza de vida de los países en 2007, basado en el conjunto de datos de <strong>Gapminder</strong>? En ese análisis, utilizamos un gráfico de dispersión para visualizar la relación entre estas dos variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gapminder)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Filtramos al 2007</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>gp2007 <span class="ot">=</span> gapminder<span class="sc">::</span>gapminder <span class="sc">%&gt;%</span> </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2007</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En el eje X colocamos la <strong>variable explicativa</strong>, el PIB per cápita (<code>gdpPerCap</code>), mientras que en el eje Y situamos la <strong>variable respuesta</strong>, la esperanza de vida (<code>lifeExp</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>g_gp2007 <span class="ot">=</span> gp2007 <span class="sc">%&gt;%</span> </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log10</span>(gdpPercap), </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> lifeExp)) <span class="sc">+</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">'darkgreen'</span>) <span class="sc">+</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  g_gp2007</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Podemos apreciar visualmente como a medida que avanzamos por el eje <span class="math inline">\(x\)</span> (mayor esperanza de vida), las observaciones <strong>tienden</strong> subir por el eje <span class="math inline">\(y\)</span> (mayor esperanza de vida).</p>
<p>Otro ejemplo clásico de análisis de regresión lo encontramos cuando queremos entender la relación entre el precio de una vivienda (variable cuantitativa) en función de determinados factores. Toma por ejemplo este conjunto de datos sobre precios de viviendas. Este conjunto contiene información sobre el precio de viviendas en Taiwan y su relación con otras variables como la distancia a la estación de METRO más cercana (<code>dist_to_mrt_m</code>, medida en metros) y el precio promedio por metro cuadrado (<code>price_twd_msq</code>, medido en dólares taiwaneses).</p>
<p>Aquí también podemos utilizar un gráfico de dispersión para explorar cómo el precio de las viviendas podría variar según la proximidad al transporte público.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>casas <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="st">'taiwan_casas.csv'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(casas)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 414
Columns: 4
$ dist_to_mrt_m   &lt;dbl&gt; 84.87882, 306.59470, 561.98450, 561.98450, 390.56840, …
$ n_convenience   &lt;dbl&gt; 10, 9, 5, 5, 5, 3, 7, 6, 1, 3, 1, 9, 5, 4, 4, 2, 6, 1,…
$ house_age_years &lt;chr&gt; "30 to 45", "15 to 30", "0 to 15", "0 to 15", "0 to 15…
$ price_twd_msq   &lt;dbl&gt; 11.467474, 12.768533, 14.311649, 16.580938, 13.040847,…</code></pre>
</div>
</div>
<p>Utilizamos <code>geom_point</code>. Dado que hay una gran superposición entre los puntos, es recomendable ajustar el parámetro <code>alpha</code> para controlar la transparencia y así mejorar la visualización, permitiendo distinguir mejor la densidad de los datos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>g_casa <span class="ot">=</span> casas <span class="sc">%&gt;%</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> dist_to_mrt_m, <span class="at">y =</span> price_twd_msq)) <span class="sc">+</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="co"># Útil para distinguir mejor la aglomeración</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span>  <span class="co"># Puntos semitransparentes en azul</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Relación entre distancia al Metro y precio por metro cuadrado"</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Distancia al metro (metros)"</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Precio (TWD/m²)"</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()  </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>g_casa</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Podemos notar un tendencia negativa conforma la distancia de la vivienda es mayor a una estación de metro. Si nuestro objetivo es analizar cómo los valores de la variable respuesta (<span class="math inline">\(y\)</span>) cambian en función de la variable explicativa (<span class="math inline">\(x\)</span>). Al observar los gráficos de dispersión, podemos identificar un patrón: parece que hay una relación entre las variables, y esta relación muestra un comportamiento que, a simple vista, podríamos <strong>aproximar como lineal</strong>. Basándonos en esta observación, proponemos que la relación entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> sea <strong>lineal</strong>, es decir, que los cambios en la variable explicativa (<span class="math inline">\(x\)</span>) produzcan <strong>cambios proporcionales</strong> (constantes) en la variable respuesta (<span class="math inline">\(y\)</span>).</p>
<section id="ecuación-de-regresión-lineal" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="ecuación-de-regresión-lineal"><span class="header-section-number">8.1.1</span> Ecuación de regresión lineal</h3>
<p>De hecho, podemos representar la linea recta que mejor represente esta relación entre las variables utilizando <code>geom_smooth</code> y definiendo un <strong>modelo lineal</strong> o linear model (lm).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>g_gp2007 <span class="sc">+</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">'Relación PBI per cápita y esperanza de vida'</span>) <span class="sc">+</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">'lm'</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'red'</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> F <span class="co"># Vamos a omitir el error </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                     <span class="co"># estándar por el mometo</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>              )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>g_casa <span class="sc">+</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">'lm'</span>, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'red'</span>,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> F)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Esta línea no es solo una herramienta visual, también nos permite <strong>aproximar</strong> cómo los cambios en una variable (la explicativa, <span class="math inline">\(x\)</span>) afectan a otra variable (la respuesta, <span class="math inline">\(y\)</span>) de forma intuitiva. Siendo una línea recta, <strong>podemos describirla con una fórmula matemática</strong>. La ecuación de la <strong>regresión lineal</strong> es la siguiente:</p>
<p><span class="math display">\[y = \alpha + \beta X\]</span></p>
<p>Donde:</p>
<p><span class="math display">\[Y(\text{variable respuesta}) = \alpha + \beta X(\text{variable explicativa})\]</span></p>
<p>Esto permite verla de forma analítica explorando cómo <span class="math inline">\(y\)</span> responde a diferentes valores de <span class="math inline">\(x\)</span>. Antes de desglosar esta fórmula, pensemos intuitivamente en qué hace esta línea:</p>
<ol type="1">
<li><p><strong>Resume un patrón general:</strong> Aunque los puntos en el gráfico pueden no alinearse perfectamente, la línea representa la tendencia principal en los datos.</p></li>
<li><p><strong>Nos permite simplificar:</strong> En lugar de observar todos los puntos dispersos en un gráfico, podemos usar esta línea para interpretar cómo las dos variables están conectadas <strong>en términos generales</strong>.</p></li>
<li><p><strong>Hace que la relación sea predecible:</strong> Una vez que tenemos la línea, podemos usarla para calcular aproximadamente qué valor de <span class="math inline">\(y\)</span> esperaríamos para un determinado valor de <span class="math inline">\(x\)</span>.</p></li>
</ol>
<p><img src="images/clipboard-3691647763.png" class="img-fluid"></p>
<p>Ahora bien, si fórmula que describe esta línea es:</p>
<p><span class="math display">\[Y(\text{variable respuesta}) = \alpha + \beta X(\text{variable explicativa})\]</span></p>
<p>Vamos a aclarar cada uno de sus componentes. Sabemos que buscamos ajustar una línea recta a los datos. Una línea recta se puede expresar en una ecuación y se definen por estas dos propiedades: su intercepto y su pendiente.</p>
<ul>
<li><span class="math inline">\(\alpha\)</span>: Es el intercepto. Es el punto donde la línea cruza el eje <span class="math inline">\(y\)</span>. Nos dice el valor de <span class="math inline">\(y\)</span> cuando <span class="math inline">\(x = 0\)</span>.</li>
<li><span class="math inline">\(\beta\)</span>: Es la inclinación o pendiente de la línea. Indica cuánto cambia <span class="math inline">\(y\)</span> en promedio, por cada unidad (1) que cambia <span class="math inline">\(x\)</span>.</li>
</ul>
<p>En el modelo, la ecuación de regresión toma estos dos elementos como los <strong>parámetros del modelo</strong>.</p>
<p>El <strong>intercepto</strong>, representado como (<span class="math inline">\(\alpha\)</span>) en la ecuación de la línea recta (<span class="math inline">\(y = \alpha + \beta x\)</span>), es el punto donde la línea cruza el eje (<span class="math inline">\(y\)</span>). Es decir, nos indica el nivel inicial de la variable dependiente (<span class="math inline">\(y\)</span>) cuando la variable independiente (<span class="math inline">\(x\)</span>) es igual a cero. En otras palabras, el intercepto nos da una idea del estado de (<span class="math inline">\(y\)</span>) en ausencia de cualquier influencia de (<span class="math inline">\(x\)</span>). En algunos casos, este valor tiene un significado práctico claro, pero en otros puede ser más abstracto, especialmente si (<span class="math inline">\(x = 0\)</span>) no tiene sentido en el contexto del problema.</p>
<p><img src="images/clipboard-2440590143.png" class="img-fluid"></p>
<p>La <strong>pendiente</strong>, representada como (<span class="math inline">\(\beta\)</span>) en la misma ecuación, describe cómo cambia la variable dependiente (<span class="math inline">\(y\)</span>) por cada unidad adicional de la variable independiente (<span class="math inline">\(x\)</span>). Dicho de otra manera, la pendiente nos indica la tasa de cambio de (<span class="math inline">\(y\)</span>) con respecto a (<span class="math inline">\(x\)</span>). Una pendiente positiva (<span class="math inline">\(\beta &gt; 0\)</span>) significa que (<span class="math inline">\(y\)</span>) aumenta a medida que (<span class="math inline">\(x\)</span>) lo hace, mostrando una relación directa entre las dos variables. Por el contrario, una pendiente negativa (<span class="math inline">\(\beta &lt; 0\)</span>) implica que (<span class="math inline">\(y\)</span>) disminuye a medida que (<span class="math inline">\(x\)</span>) aumenta, lo que refleja una relación inversa. Si la pendiente es igual a cero (<span class="math inline">\(\beta = 0\)</span>), significa que (<span class="math inline">\(y\)</span>) no cambia en absoluto con (<span class="math inline">\(x\)</span>), lo que indica que las dos variables no están relacionadas.</p>
<p><img src="images/clipboard-3572669114.png" class="img-fluid"></p>
<p>Mientras el intercepto determina el punto de inicio de la línea en el eje (<span class="math inline">\(y\)</span>), la pendiente define su inclinación. El hecho de que podamos asignarle una ecuación a la relación cuantificarla y hacer predicciones. Por ejemplo, sabiendo el intercepto y la pendiente, podemos calcular el valor esperado de (<span class="math inline">\(y\)</span>) para cualquier valor de (<span class="math inline">\(x\)</span>).</p>
<p>Para el caso de las viviendas:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>g_casa <span class="sc">+</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">'lm'</span>, </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'red'</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> F)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Puedes interactuar con los parámetros de la ecuación lineal en la <strong>Datáfora Interactiva</strong>: [<a href="https://np6xsv-gonzalo-almendariz.shinyapps.io/dinstats/">Click Aquí</a>]</p>
<p>O usa el QR:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/QR_Code_1745519927.png" class="img-fluid figure-img" width="85"></p>
<figcaption>Dirígete a la pestaña Regresión lineal</figcaption>
</figure>
</div>
<p>En R podemos ajustar el modelo de regresión lineal y extraer los parametros de ecuación usando <code>lm()</code>. Su estructura básica sigue la lógica de una fórmula: <code>lm(y ~ x, data = ...)</code>, donde <code>y</code> representa la variable dependiente o respuesta, y <code>x</code> la variable independiente. El símbolo <code>~</code> se lee como “explicado por” o “en función de”, por lo que la expresión <code>y ~ x</code> indica que estamos tratando de explicar los valores de <code>y</code> a partir de los valores de <code>x</code>. El argumento <code>data = ...</code> especifica el nombre del data frame donde se encuentran esas variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustamos el modelo lineal</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">=</span> <span class="fu">lm</span>(price_twd_msq <span class="sc">~</span> dist_to_mrt_m, <span class="at">data =</span> casas)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Vemos los coeficientes (intercepto y pendiente)</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(modelo)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept) dist_to_mrt_m 
 13.873351606  -0.002197292 </code></pre>
</div>
</div>
<p>Con esta información, ya podemos escribir la ecuación del modelo muestral:</p>
<p><span class="math display">\[
\text{Precio de la vivienda} = 13.87 - 0.0022 \cdot \text{Distancia en }m^2
\]</span></p>
<p>Esto significa que, en base a la información que tenemos disponible sobre las viviendas, <strong>la pendiente del modelo</strong> es <span class="math inline">\(-0.0022\)</span>. Es decir, <strong>por cada metro adicional de distancia a la estación de metro</strong>, el precio promedio por metro cuadrado <strong>disminuye</strong> en alrededor de 0.0022 dólares taiwaneses. Por otro lado, <strong>el intercepto</strong> es <span class="math inline">\(13.87\)</span>, lo que indica que cuando la distancia a la estación es cero (es decir, en una vivienda ubicada justo al lado del metro, <span class="math inline">\(x=0\)</span>) el precio estimado por metro cuadrado sería de 13.87 dólares taiwaneses. Si bien en la práctica puede que no existan viviendas exactamente a cero metros del metro, este valor nos da una referencia inicial del modelo y completa la ecuación de la línea recta ajustada.</p>
<p>Aunque esta <strong>representación matemática</strong> puede parecer un poco abstracta al principio, es simplemente una manera formal de expresar algo que podemos ver intuitivamente en el gráfico. La línea recta nos ayuda a simplificar y entender mejor los patrones en nuestros datos. Sin embargo, como toda <strong>simplificación</strong>, debemos ser conscientes de sus <strong>limitaciones</strong>: no todos los puntos se alinean perfectamente con la línea, por lo que la relación que estamos estableciendo es una <strong>aproximación</strong>. Todos los modelos son aproximaciones simples de la realidad. <strong>Un modelo es, en esencia, una representación simplificada de la relación entre variables en una población</strong>. Nos ayuda a interpretar patrones observados en los datos.</p>
<p>Sin embargo, es fundamental destacar que este tipo de modelos <strong>no pretende capturar toda la complejidad de la realidad</strong>. Más bien, funcionan como una <strong>herramienta para aproximarnos a las relaciones observadas en los datos</strong>. Es crucial recordar que <strong>correlación no implica causalidad</strong>, y que la relación entre variables dentro de un modelo estadístico no siempre refleja un vínculo de causa y efecto.</p>
<p>Por ejemplo, si un modelo muestra que un mayor <strong>PIB per cápita</strong> se asocia con una mayor <strong>esperanza de vida</strong>, esto no significa que un país pueda simplemente aumentar su PIB per cápita y, como resultado directo, su población vivirá más tiempo. Lo que el modelo realmente indica es que, según los datos disponibles, al comparar dos países, aquel con un PIB per cápita más alto <strong>tiende</strong> a presentar una mayor esperanza de vida. Sin embargo, esto <strong>no implica que el PIB sea el único elemento asociado</strong> a esta diferencia, sino que señala una relación observada en los datos, la cual puede estar influenciada por múltiples factores adicionales (debemos ser muy cautos al interpetar estos modelos como asociaciónes, no causas)</p>
<p>Otro elementos importante a considerar es que, <strong>no todas las relaciones entre variables son lineales</strong>, por lo que antes de ajustar un modelo de regresión, es <strong>fundamental visualizar los datos</strong> mediante un gráfico de dispersión. Esto permite identificar si la relación observada puede representarse adecuadamente con una línea recta o si, por el contrario, sería más apropiado considerar otro tipo de modelado.</p>
<p><img src="images/clipboard-3431157632.png" class="img-fluid"></p>
<p>Por ejemplo, en ambos casos, aunque es posible ajustar una línea recta para describir la relación, se observa claramente que esta <strong>no captura correctamente el patrón de los datos</strong> para el primer caso. En consecuencia, una regresión lineal no sería el modelo más adecuado, y sería necesario explorar alternativas que reflejen mejor la estructura de la relación entre las variables.</p>
<p>De hecho, podemos recurrir a otros métodos para construir modelos (aproximaciones de la realidad) que no dependan de una fórmula lineal. <strong>LOESS (Local Regression Smoothing)</strong>, por ejemplo, es un enfoque no paramétrico que permite suavizar los datos y detectar tendencias en relaciones no lineales entre variables. A diferencia de la regresión lineal tradicional, que impone una relación global fija en todo el conjunto de datos, LOESS realiza múltiples ajustes locales sobre subconjuntos, asignando mayor peso a los puntos cercanos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>g_gp2007 <span class="sc">+</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">'Relación PBI per cápita y esperanza de vida'</span>) <span class="sc">+</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">'loess'</span>, <span class="co"># Metodo loess en ves de lm</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'red'</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> F </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>              )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>g_casa <span class="sc">+</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">'loess'</span>, </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'red'</span>, </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Ahora bien, aunque métodos como LOESS pueden ofrecer una representación más precisa de la relación entre variables, especialmente cuando esta no es lineal, su principal desventaja es que resultan menos interpretables, ya que no generan una ecuación clara que podamos analizar o comunicar fácilmente (como la ecuación lineal).</p>
<p>Por esta razón, y con el objetivo de facilitar la comprensión del modelo, en esta etapa nos centraremos únicamente en las <strong>regresiones lineales simples</strong>, que si bien pueden ser menos precisas en algunos casos, permiten identificar patrones generales de forma directa y facilmente interpetable. Estoy seguro de que puede proporcionará un punto de partida útil para el propósito de este libro, pero ten en cuenta de que no es el único.</p>
</section>
<section id="mínimos-cuadrados-ordinarios-ols" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="mínimos-cuadrados-ordinarios-ols"><span class="header-section-number">8.1.2</span> Mínimos cuadrados ordinarios (OLS)</h3>
<p>Ahora que entendemos la utilidad de una línea recta para modelar relaciones entre variables, el siguiente paso es preguntarnos: ¿cómo se determina esa línea? ¿De dónde sale y cómo sabemos cuál es la más representativa de la relación observada en los datos? Esta línea no se elige al azar, sino que se construye a partir de un método formal conocido como <strong>Mínimos Cuadrados Ordinarios</strong> (OLS, por sus siglas en inglés). El objetivo del OLS es encontrar los valores óptimos del intercepto (<span class="math inline">\(\alpha\)</span>) y la pendiente (<span class="math inline">\(\beta\)</span>) que definan la línea recta que mejor se ajusta a los datos observados, minimizando la suma de los errores al cuadrado entre los valores reales y los valores predichos por el modelo.</p>
<p>Pero, ¿qué significa “mejor ajuste”? Intuitivamente, queremos que la línea esté lo más cerca posible de todos los puntos del gráfico. Para lograr esto, el OLS minimiza la suma de los <strong>errores al cuadrado</strong>. El “error” en este contexto se refiere a la distancia vertical entre un punto observado (<span class="math inline">\(y_i\)</span>) y el valor predicho por la línea (<span class="math inline">\(\hat{y}_i\)</span>). Representa cuánto se desvía el modelo de los datos reales en cada punto.</p>
<p><img src="images/clipboard-1001252891.png" class="img-fluid"></p>
<p>Si un punto está exactamente sobre la línea, el error es cero, si está por encima o por debajo, el error indica cuánto el modelo subestimó o sobreestimó el valor real. El error captura las imperfecciones del modelo. Es decir:</p>
<p><span class="math display">\[
\text{Error} = y_i - \hat{y}_i
\]</span></p>
<p>Donde:</p>
<ul>
<li><p>(<span class="math inline">\(y_i\)</span>) es el valor observado de la variable dependiente para un punto específico.</p></li>
<li><p>(<span class="math inline">\(\hat{y}_i\)</span>) es el valor predicho por la línea para el mismo punto.</p></li>
</ul>
<p>El método OLS eleva al cuadrado estas diferencias y luego suma todos los valores. Esto da como resultado una métrica conocida como la <strong>suma de los errores al cuadrado</strong>. El OLS ajusta la línea recta de manera que esta suma sea lo más pequeña posible. En otras palabras, la línea resultante es aquella que minimiza la diferencia total entre los valores observados y los valores predichos.</p>
<p><span class="math display">\[
\text{Suma de errores al cuadrado} = \sum (y_i - \hat{y}_i)^2
\]</span></p>
<p>Pero ¿por qué minimizamos el cuadrado de los errores y no simplemente los errores? Elevarlos al cuadrado tiene dos ventajas importantes:</p>
<ol type="1">
<li>Penaliza más los errores grandes, lo que asegura que la línea no esté significativamente lejos de ningún punto.</li>
<li>Convierte todos los errores en valores positivos, lo que evita que los errores positivos y negativos se anulen mutuamente.</li>
</ol>
<p>Este método asegura que la línea recta que obtenemos sea, en cierto sentido, la “mejor representación posible” de los datos según el criterio de los mínimos cuadrados. Al aplicar el OLS, establecemos la linea recta adecuada para nuestras observaciones y, en consecuencia, podemos determinar numéricamente los valores del intercepto (<span class="math inline">\(\alpha\)</span>) y la pendiente (<span class="math inline">\(\beta\)</span>) que la definen.</p>
</section>
<section id="desviación-estándar-condicional" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="desviación-estándar-condicional"><span class="header-section-number">8.1.3</span> Desviación estándar condicional</h3>
<p>Cuando usamos una línea de regresión para describir la relación entre dos variables, debemos recordar que no estamos representando los datos de manera exacta. La línea de regresión es una aproximación que resume, de forma promedio, cómo se relacionan las variables (<span class="math inline">\(x\)</span>) (predictora) e (<span class="math inline">\(y\)</span>) (respuesta). En realidad, los puntos de los datos suelen estar dispersos alrededor de esta línea, lo que significa que existe variación en los valores reales de (<span class="math inline">\(y\)</span>) para cada (<span class="math inline">\(x\)</span>).</p>
<p>Para capturar esta dispersión, el modelo introduce un parámetro adicional, (<span class="math inline">\(\sigma\)</span>), que representa la <strong>desviación estándar condicional</strong>. Este parámetro mide, en promedio, cuánto varían los valores de (<span class="math inline">\(y\)</span>) respecto a la línea de regresión para un valor dado de (<span class="math inline">\(x\)</span>). Si (<span class="math inline">\(\sigma\)</span>) es pequeño, significa que los puntos están más cerca de la línea y que el modelo describe mejor la relación entre las variables. Por el contrario, si (<span class="math inline">\(\sigma\)</span>) es grande, la dispersión alrededor de la línea es mayor, lo que indica que el modelo es menos preciso en su descripción.</p>
<p><img src="images/clipboard-1868849460.png" class="img-fluid"></p>
<p>Es importante resaltar que en este modelo estamos asumiendo que la <strong>desviación estándar condicional</strong>, representada por <span class="math inline">\(\sigma\)</span>, es la misma para todos los valores de <span class="math inline">\(x\)</span>. Esto significa que la cantidad de variación de los valores de <span class="math inline">\(y\)</span> alrededor de la línea de regresión es <strong>constante en todo el rango de</strong> <span class="math inline">\(x\)</span>, una condición conocida como <strong>homocedasticidad</strong>. En otras palabras, independientemente del valor de <span class="math inline">\(x\)</span>, se espera que la dispersión de los puntos alrededor de la línea siga siendo similar.</p>
<p>Pero, ¿qué significa esto realmente? Tomando como ejemplo la relación entre el precio de una vivienda y la distancia a la estación de metro, debemos tener en cuenta que al ajustar una línea recta no estamos diciendo que <strong>cada valor de</strong> <span class="math inline">\(x\)</span> se asocie con un único valor exacto de <span class="math inline">\(y\)</span>, sino que la línea representa el <strong>valor promedio esperado de</strong> <span class="math inline">\(y\)</span> para cada valor de <span class="math inline">\(x\)</span>. Es decir, no es una predicción exacta, sino una tendencia general.</p>
<p>Podemos extraerlo de la siguiente forma</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)<span class="sc">$</span>sigma</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.046457</code></pre>
</div>
</div>
<p>Este valor significa que, en promedio, los precios reales por metro cuadrado se desvían unos 3.05 dólares taiwaneses del valor estimado por el modelo. Por ahora, nos enfocamos en entender que este modelo es solo una aproximación, y que <span class="math inline">\(\sigma\)</span> nos da una idea clave de cuánta variabilidad existe alrededor de esa tendencia. Más adelante, abordaremos con más detalle estas suposiciones y su impacto en el análisis y la interpretación de los resultados.</p>
</section>
<section id="la-correlación-y-la-pendiente" class="level3" data-number="8.1.4">
<h3 data-number="8.1.4" class="anchored" data-anchor-id="la-correlación-y-la-pendiente"><span class="header-section-number">8.1.4</span> La correlación y la pendiente</h3>
<p>Para poder evaluar la calidad del ajuste del modelo podemos utilizar una métrica que ya hemos visto previamente: el coeficiente de correlación de Pearson. Como discutimos en el capítulo de estadística descriptiva, este indicador no solo mide la fuerza y la dirección de la relación entre las variables, sino que también nos da una idea de qué tan lineal es dicha relación. Una correlación cercana a 1 o -1 indica que los puntos están cerca de la línea de regresión, mientras que valores más bajos sugieren mayor dispersión alrededor de la línea.</p>
<p>Sabemos que la pendiente (<span class="math inline">\(\beta\)</span>) de la línea de regresión nos dice en qué dirección va la relación (positiva o negativa) y cuánto cambia la variable dependiente (<span class="math inline">\(y\)</span>) por cada unidad de cambio en la variable independiente (<span class="math inline">\(x\)</span>). Sin embargo, debemos ser cuidadosos al interpretar la pendiente como una medida de la fuerza de la relación. La razón de esto es que el valor numérico de la pendiente depende de las unidades en las que estén medidas las variables.</p>
<p><span class="citation" data-cites="agresti2018">Agresti (<a href="references.html#ref-agresti2018" role="doc-biblioref">2018</a>)</span>, en <em>Statistical Methods for the Social Sciences</em>, ilustra claramente cómo <span class="math inline">\(\beta\)</span> depende de las unidades de medición. Supongamos que <span class="math inline">\(y\)</span> representa la tasa de homicidios por cada 100,000 habitantes y <span class="math inline">\(x\)</span> es el porcentaje de personas que viven bajo la línea de pobreza. En este caso, una ecuación de regresión podría ser:</p>
<p><span class="math display">\[
\hat{y} = -0.86 + 0.58x
\]</span></p>
<p>Aquí, la pendiente (<span class="math inline">\(\beta = 0.58\)</span>) significa que, por cada incremento de (1%) en la pobreza (<span class="math inline">\(x\)</span>), se espera un aumento de 0.58 homicidios por cada 100,000 habitantes en la tasa de homicidios (<span class="math inline">\(y\)</span>). Sin embargo, si cambiamos las unidades de medición de (<span class="math inline">\(y\)</span>) para expresar la tasa de homicidios por cada 1,000,000 habitantes, el valor de la pendiente también cambia. Como (<span class="math inline">\(1,000,000\)</span>) es 10 veces (<span class="math inline">\(100,000\)</span>), la pendiente se multiplicará por 10, resultando en:</p>
<p><span class="math display">\[
\beta = 5.8
\]</span></p>
<p>Esto significa que ahora, por cada incremento de (<span class="math inline">\(1 \%\)</span>) en la pobreza, se espera un aumento de 5.8 homicidios por cada 1,000,000 habitantes.</p>
<p>Es importante notar que este cambio en la pendiente no altera la relación entre las variables, ya que esta depende exclusivamente de los datos subyacentes y no de las unidades en que se expresan. El cambio afecta únicamente la escala de la pendiente, no la fuerza o naturaleza intrínseca de la asociación. Por ello, no debemos interpretar (<span class="math inline">\(\beta\)</span>) como una medida de la fuerza de la relación, ya que su valor puede ser manipulado simplemente cambiando las unidades de las variables.</p>
<p>Aquí es donde el <em>coeficiente de correlación</em> (<span class="math inline">\(r\)</span>) se vuelve especialmente útil. A diferencia de la pendiente (<span class="math inline">\(\beta\)</span>), el valor de (<span class="math inline">\(r\)</span>) no depende de las unidades de medición. Esto significa que, sin importar cómo midamos las variables (<span class="math inline">\(x\)</span>) e (<span class="math inline">\(y\)</span>), ya sea en porcentajes, tasas o cantidades absolutas, el coeficiente de correlación siempre será el mismo. Aunque el cálculo detrás de (<span class="math inline">\(r\)</span>) implica ciertos ajustes matemáticos para tomar en cuenta la variabilidad de las variables, no es necesario conocer esos detalles para entender su utilidad. Por lo tanto, aunque la pendiente es útil para interpretar el efecto de (<span class="math inline">\(x\)</span>) sobre (<span class="math inline">\(y\)</span>) en términos absolutos, el coeficiente de correlación proporciona una medida estándar que nos permite comparar la fuerza de las relaciones entre diferentes pares de variables, independientemente de sus unidades.</p>
<p>Puedes interactuar con la correlación en la <strong>Datáfora Interactiva</strong>: [<a href="https://np6xsv-gonzalo-almendariz.shinyapps.io/dinstats/">Click Aquí</a>]</p>
<p>O usa el QR:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/QR_Code_1745519927.png" class="img-fluid figure-img" width="85"></p>
<figcaption>Dirígete a la pestaña Correlación</figcaption>
</figure>
</div>
</section>
<section id="coeficiente-de-determinación" class="level3" data-number="8.1.5">
<h3 data-number="8.1.5" class="anchored" data-anchor-id="coeficiente-de-determinación"><span class="header-section-number">8.1.5</span> Coeficiente de determinación</h3>
<p>Una vez que ajustamos el modelo, es natural preguntarse qué tan bien está funcionando. Para eso usamos el <strong>coeficiente de determinación</strong>, representado como <span class="math inline">\(r^2\)</span>. Esta medida nos dice qué proporción de la variabilidad de la variable dependiente (<span class="math inline">\(y\)</span>) puede ser explicada por la variable independiente (<span class="math inline">\(x\)</span>).</p>
<p>Para entenderlo, se comparan dos enfoques para predecir <span class="math inline">\(y\)</span>. El primero consiste en usar únicamente el promedio de <span class="math inline">\(y\)</span> (<span class="math inline">\(\bar{y}\)</span>) como predicción constante, sin tomar en cuenta <span class="math inline">\(x\)</span>. Esto genera una predicción básica pero no considera ninguna relación entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. El segundo enfoque utiliza la ecuación de regresión:</p>
<p><span class="math display">\[
y = \alpha + \beta X
\]</span></p>
<p>Esta ecuación incorpora la relación observada entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, ajustando las predicciones según los valores de <span class="math inline">\(x\)</span>. La utilidad del modelo de regresión se evalúa midiendo cuánto se reducen los errores de predicción al pasar de usar <span class="math inline">\(\bar{y}\)</span> como predicción a usar <span class="math inline">\(\hat{y}\)</span>.</p>
<p>El cálculo de <span class="math inline">\(r^2\)</span> se basa en la proporción de reducción del error. Primero, se mide el error total al usar <span class="math inline">\(\bar{y}\)</span> para predecir <span class="math inline">\(y\)</span>, llamado <em>suma total de cuadrados</em> (<span class="math inline">\(TSS\)</span>):</p>
<p><span class="math display">\[
TSS = \sum (y - \bar{y})^2
\]</span></p>
<p>Luego, se mide el error al usar la ecuación de regresión, llamado <em>suma de cuadrados de los errores</em> (<span class="math inline">\(SSE\)</span>):</p>
<p><span class="math display">\[
SSE = \sum (y - \hat{y})^2
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>La reducción relativa del error se calcula como:</p>
<p><span class="math display">\[
r^2 = \frac{TSS - SSE}{TSS}
\]</span></p>
<p>Pero, ¿qué significa esto de forma más intuitiva? Volviendo al ejemplo de las viviendas, imagina que estás tratando de predecir el precio de una vivienda en función de su distancia a la estación de metro. Puedes extrar el coefiecente de la siguiente forma:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)<span class="sc">$</span>r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4537543</code></pre>
</div>
</div>
<p>Si obtenemos un <span class="math inline">\(r^2 = 0.45\)</span>, esto quiere decir que <strong>el 45% de la variabilidad</strong> en los precios puede explicarse solo a partir de la distancia a la estación de metro. En otras palabras, <strong>conocer cuán lejos está una vivienda del metro sí aporta información útil sobre su precio</strong>, pero también nos deja claro que <strong>el 55% restante de la variabilidad se debe a otros factores</strong> no incluidos en el modelo, como el tamaño del inmueble, su estado de conservación, el nivel socioeconómico de la zona, o simplemente a variaciones aleatorias.</p>
<p>Para capturar una mayor proporción de esa variabilidad, será necesario realizar nuevas evaluaciones e <strong>incorporar más variables al modelo</strong>, algo que abordaremos más adelante en el apartado dedicado a la <strong>regresión múltiple</strong>.</p>
</section>
<section id="resumen-del-modelo-en-r-con-summary" class="level3" data-number="8.1.6">
<h3 data-number="8.1.6" class="anchored" data-anchor-id="resumen-del-modelo-en-r-con-summary"><span class="header-section-number">8.1.6</span> Resumen del modelo en R con <code>summary()</code></h3>
<p>En R podemos ajustar el modelo con <code>lm()</code>, y una vez que le asignamos un nombre, podemos usar <code>summary()</code> para obtener un <strong>resumen completo</strong> que incluye todos los elementos que hemos comentado hasta el momento y algunos más.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = price_twd_msq ~ dist_to_mrt_m, data = casas)

Residuals:
     Min       1Q   Median       3Q      Max 
-10.7097  -1.8177  -0.3617   1.4616  22.2338 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   13.8733516  0.1974616   70.26   &lt;2e-16 ***
dist_to_mrt_m -0.0021973  0.0001188  -18.50   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 412 degrees of freedom
Multiple R-squared:  0.4538,    Adjusted R-squared:  0.4524 
F-statistic: 342.2 on 1 and 412 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Intercepto.png" class="img-fluid figure-img"></p>
<figcaption>Elaboración propia</figcaption>
</figure>
</div>
<p>En la imagen podemos observar claramente los valores estimados para los parámetros del modelo: el <strong>intercepto</strong> y la <strong>pendiente</strong>, que se encuentran en la parte superior de la tabla. Justo al costado de cada uno, también aparecen otras columnas con información adicional como el <strong>error estándar (Std. Error)</strong>, el <strong>valor t (t value)</strong> y el <strong>valor p (Pr(&gt;|t|))</strong>, que nos permiten hacer inferencias estadísticas sobre estos coeficientes. Por ahora, dejaremos esos elementos para la siguiente sección del capítulo, donde los abordaremos con más detalle.</p>
<p>En la parte inferior del resumen, se presentan dos indicadores importantes que ya hemos discutido: la <strong>desviación estándar condicional</strong> (Residual standard error), que nos dice cuánto tienden a desviarse los valores reales de los valores estimados por el modelo, y el <strong>coeficiente de determinación</strong> <span class="math inline">\(r^2\)</span>, que mide qué proporción de la variabilidad total en el precio por metro cuadrado es explicada por la distancia a la estación de metro.</p>
</section>
</section>
<section id="inferencia-de-coeficientes-para-el-modelo-lineal" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="inferencia-de-coeficientes-para-el-modelo-lineal"><span class="header-section-number">8.2</span> Inferencia de coeficientes para el modelo lineal</h2>
<p>Hasta este punto, ya hemos explorado todas las características de un modelo lineal: cómo se ajusta, qué representa y cómo evaluamos su desempeño. Sin embargo, al igual que sucede con los resúmenes estadísticos como la media o la desviación estándar, en la práctica <strong>no trabajamos con toda la población</strong>, sino con una muestra limitada de datos. Esto significa que el modelo lineal que construimos no es el modelo de la población, sino una <strong>estimación</strong> basada en los datos a los que tuvimos acceso (la muestra). Y aquí es donde entra en juego la inferencia: lo que nos interesa ahora no es solo ajustar una línea, sino preguntarnos si <strong>esa relación entre las dos variables que observamos en la muestra es suficientemente fuerte o consistente como para pensar que también existe en la población completa</strong>. En este contexto, la fórmula cambia ligeramente, porque lo que estamos evaluando ya no es solo el modelo ajustado, sino <strong>la plausibilidad de esa relación a nivel poblacional</strong>.</p>
<p>En el caso de la regresión lineal, cuando hablamos del <strong>modelo poblacional</strong>, la relación entre las variables se expresa de la siguiente manera:</p>
<p><span class="math display">\[
Y = \alpha + \beta X
\]</span></p>
<p>Aquí, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span> son <strong>parámetros poblacionales desconocidos</strong>, es decir, todas aquellas influencias sobre <span class="math inline">\(Y\)</span> que no se explican a través de <span class="math inline">\(X\)</span>. Sin embargo, como <strong>en la práctica no tenemos acceso a toda la población</strong>, lo que hacemos es trabajar con una muestra y, por lo tanto, estimar esos parámetros a partir de los datos disponibles.Es por ello que el modelo cambia de forma y se convierte en una versión estimada:</p>
<p><span class="math display">\[
\hat{Y} = a + bX
\]</span></p>
<p>En esta nueva expresión, <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> son los <strong>estadísticos muestrales</strong> que usamos para aproximar a <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>, respectivamente. Es decir, son los valores que obtenemos al aplicar el método de Mínimos Cuadrados Ordinarios (OLS) sobre nuestra muestra. La diferencia entre el valor real <span class="math inline">\(Y\)</span> y el valor estimado <span class="math inline">\(\hat{Y}\)</span> ahora se denomina <strong>residuo</strong>, y se representa con:</p>
<p><span class="math display">\[
e = Y - \hat{Y}
\]</span></p>
<p>Este cambio de notación no es solo simbólico: refleja una transición fundamental en la forma de pensar el modelo. Ya no estamos afirmando con certeza cómo se comporta la población, sino construyendo una <strong>estimación con incertidumbre</strong> basada en los datos que tenemos.</p>
<p>Ahora que contamos con los valores estimados <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, en lugar de los parámetros poblacionales <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>, el objetivo pasa a ser <strong>poner a prueba la existencia de una relación lineal entre las variables</strong>. Para ello, utilizamos las herramientas de la inferencia: la <strong>estimación</strong> y el <strong>contraste de hipótesis</strong>, que ya conocemos por otros contextos, como el análisis de medias o proporciones.</p>
<p>En este caso, nos centraremos especialmente en el <strong>estadístico</strong> <span class="math inline">\(b\)</span>, que es la estimación puntual del parámetro <span class="math inline">\(\beta\)</span>. Recordemos que <span class="math inline">\(\beta\)</span> nos da información clave sobre la <strong>dirección</strong> y <strong>magnitud</strong> de la relación entre las variables: si <span class="math inline">\(\beta &gt; 0\)</span>, la relación es creciente; si <span class="math inline">\(\beta &lt; 0\)</span>, es decreciente; y si <span class="math inline">\(\beta = 0\)</span>, no hay relación lineal.</p>
<p>Al igual que otros estadísticos, <span class="math inline">\(b\)</span> está sujeto a variabilidad muestral y, gracias al <strong>Teorema del Límite Central (TLC)</strong>, sabemos que, bajo ciertas condiciones, su distribución se aproxima a una <strong>distribución normal</strong>. Esto nos permite aplicar la misma intuición que usamos con otros estadísticos: construir un <strong>intervalo de confianza</strong> alrededor del valor observado de <span class="math inline">\(b\)</span> y realizar un <strong>contraste de hipótesis</strong>.</p>
<section id="estimación-de-la-pendiente" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="estimación-de-la-pendiente"><span class="header-section-number">8.2.1</span> Estimación de la pendiente</h3>
<p>Una vez que hemos ajustado nuestro modelo de regresión lineal simple, lo que obtenemos en la práctica no es el verdadero parámetro poblacional <span class="math inline">\(\beta\)</span>, sino una <strong>estimación muestral</strong>, a la que llamamos <span class="math inline">\(b\)</span>. Como hemos visto, <span class="math inline">\(b\)</span> representa la <strong>pendiente de la recta ajustada</strong> y nos indica cuánto cambia, en promedio, la variable dependiente <span class="math inline">\(y\)</span> por cada unidad de cambio en la variable independiente <span class="math inline">\(x\)</span>.</p>
<p>Pero, como toda estimación basada en una muestra, <span class="math inline">\(b\)</span> está sujeta a <strong>variabilidad muestral</strong>. Es decir, si tomáramos otra muestra diferente de la población, obtendríamos un valor distinto de <span class="math inline">\(b\)</span>. Para poder trabajar con esta incertidumbre, recurrimos a técnicas de inferencia estadística que nos permiten construir <strong>intervalos de confianza</strong> alrededor del valor observado de <span class="math inline">\(b\)</span>.</p>
<p>Bajo determinados supuestos que el modelo lineal clásico establece (linealidad, independencia, homocedasticidad y normalidad del error), el estadístico <span class="math inline">\(b\)</span> se distribuye aproximadamente como una normal. Con esa información, podemos construir un <strong>intervalo de confianza al 95%</strong> para <span class="math inline">\(\beta\)</span>, utilizando la distribución t de Student con <span class="math inline">\(n - 2\)</span> grados de libertad:</p>
<p><span class="math display">\[
IC_{95\%}(\beta) = b \pm t_{(1 - \alpha/2, \, n - 2)} \cdot \text{EE}(b)
\]</span></p>
<p>Este intervalo nos da un rango plausible de valores para el verdadero <span class="math inline">\(\beta\)</span> en la población, asumiendo que el modelo está bien especificado y que los supuestos se cumplen. Recuerda que para in intervalo de confianza es fundamental conocer el Error Estándar: <span class="math inline">\(\text{SE}(b)\)</span>. Este valor nos da una idea de <strong>cuánta incertidumbre hay en la estimación de la pendiente</strong>. Mientras más pequeño sea el error estándar, más precisa será nuestra estimación y más estrecho será el intervalo. La fórmula es algo más complicada por lo que, para mantener la simplicidad del libro, no nos centraremos en ella. R ya se encarga de hacer este cálculo por nosotros al ajustar el modelo, por lo que en este capítulo <strong>nos enfocaremos únicamente en interpretar el resultado</strong> y en comprender lo que significa en el contexto del análisis.</p>
<p>Para nuestro nuestro modelo de viviendas podemos ver que para nuestra variable <code>dist_to_mrt_m</code> la columna <code>Std. Error</code> nos indica el EE</p>
<p><img src="images/Intercepto-2.png" class="img-fluid"></p>
<p>Con el valor estimado de la pendiente <span class="math inline">\(b = -0.0021973\)</span> y su error estándar <span class="math inline">\(\text{SE}(b) = 0.0001188\)</span>, podemos construir manualmente un <strong>intervalo de confianza al 95%</strong> para el parámetro poblacional <span class="math inline">\(\beta\)</span>.</p>
<p>Recordemos que al usar un nivel de confianza del 95%, estamos dejando un <strong>2.5% de probabilidad en cada extremo de la distribución t</strong>, por lo que buscamos el <strong>cuantil</strong> <span class="math inline">\(t_{(1 - \alpha/2)} = t_{0.975}\)</span>, considerando los <strong>grados de libertad</strong> <span class="math inline">\(df = n - 2\)</span> (en regresión lineal simple, siempre restamos 2: uno por la pendiente y otro por el intercepto).</p>
<p>Sabemos que el modelo se ha ajustado con 414 observaciones, por lo que los <strong>grados de libertad</strong> del modelo son:</p>
<p><span class="math display">\[
df = 414 - 2 = 412
\]</span></p>
<p>Al trabajar con un <strong>nivel de confianza del 95%</strong>, estamos dejando un 5% de probabilidad repartida en ambos extremos de la distribución, es decir, <strong>2.5% a cada lado</strong>. Por eso usamos el valor crítico de la distribución t de Student para <span class="math inline">\(df = 412\)</span> y una cola de 2.5%:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="dv">412</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.965739</code></pre>
</div>
</div>
<p>Con esto, el intervalo de confianza se construye como:</p>
<p><span class="math display">\[
IC_{95\%}(\beta) = b \pm t_{(0.975, df=412)} \cdot \text{SE}(b)
\]</span></p>
<p>Sustituyendo los valores:</p>
<p><span class="math display">\[
IC_{95\%}(\beta) = -0.0021973 \pm 1.966885 \cdot 0.0001188
\]</span></p>
<p>Calculamos el margen de error:</p>
<p><span class="math display">\[
1.966885 \cdot 0.0001188 \approx 0.0002337
\]</span></p>
<p>Por lo tanto, el intervalo de confianza es:</p>
<p><span class="math display">\[
[-0.002431, \; -0.001964]
\]</span></p>
<p>Esto significa que, con un 95% de confianza, <strong>el valor verdadero de la pendiente poblacional</strong> <span class="math inline">\(\beta\)</span> se encuentra entre <span class="math inline">\(-0.002431\)</span> y <span class="math inline">\(-0.001964\)</span>.</p>
</section>
<section id="prueba-de-independencia-contraste-de-hipótesis-sobre-beta" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="prueba-de-independencia-contraste-de-hipótesis-sobre-beta"><span class="header-section-number">8.2.2</span> Prueba de independencia: contraste de hipótesis sobre <span class="math inline">\(\beta\)</span></h3>
<p>Además de estimar un intervalo para <span class="math inline">\(\beta\)</span>, también podemos realizar un <strong>contraste de hipótesis formal</strong> para evaluar si la relación observada entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> es estadísticamente significativa. En este contexto, llevar a cabo una <strong>prueba de independencia</strong> implica preguntarnos si la relación que vemos en los datos es lo suficientemente consistente como para pensar que <strong>no se debe simplemente al azar</strong>.</p>
<p>Al igual que en otros contrastes que hemos trabajado, partimos de la <strong>hipótesis nula (</strong><span class="math inline">\(H_0\)</span>), que plantea la <strong>ausencia de efecto</strong>, es decir, que no existe una relación lineal entre las variables. En términos del modelo, esta hipótesis se formula como que la <strong>pendiente poblacional es cero</strong>, es decir, <span class="math inline">\(\beta = 0\)</span>. Frente a esta, la <strong>hipótesis alternativa (</strong><span class="math inline">\(H_1\)</span>) sostiene que sí hay un efecto, es decir, que la pendiente es distinta de cero y, por tanto, <strong>sí existe una relación lineal significativa entre</strong> <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
<p>Por lo tanto, planteamos las hipótesis de la siguiente forma:</p>
<ul>
<li><p>Hipótesis nula:<br>
<span class="math display">\[
H_0: \beta = 0
\]</span> No hay relación lineal en la población; <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> son independientes.</p></li>
<li><p>Hipótesis alternativa:<br>
<span class="math display">\[
H_1: \beta \neq 0
\]</span> Existe una relación lineal entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p></li>
</ul>
<p>Donde el estadístico <span class="math inline">\(t\)</span> para este contraste se calcula como:</p>
<p><span class="math display">\[
t = \frac{b - 0}{\text{SE}(b)}
\]</span></p>
<p>Este valor nos indica <strong>cuántas desviaciones estándar se encuentra</strong> <span class="math inline">\(b\)</span> por encima o por debajo de 0, y se conoce como <strong>estadístico t</strong>. Lo comparamos con una <strong>distribución t de Student</strong> con <span class="math inline">\(n - 2\)</span> grados de libertad, ya que en regresión lineal simple estimamos dos parámetros: el intercepto y la pendiente. En el resumen del modelo, este valor aparece en la columna <code>t value</code>.</p>
<p><img src="images/Intercepto-3.png" class="img-fluid"></p>
<p>Al tener un <span class="math inline">\(t\)</span>-valor de -18.5, podemos observar que la probabilidad de tener un <span class="math inline">\(\beta\)</span> como el de nuestra muestra bajo <span class="math inline">\(H_0\)</span> es extremamente bajo. Podemos calcularlo para ser más exactos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pt</span>(<span class="sc">-</span><span class="fl">18.5</span>, <span class="at">df =</span> <span class="dv">412</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.313134e-56</code></pre>
</div>
</div>
<p>De hecho, si observas bien, ya está calculado al lado.</p>
<p>Siguiendo la lógica de pruebas anteriores, el <strong>valor p</strong> asociado a ese estadístico <span class="math inline">\(t\)</span> nos da la <strong>probabilidad de obtener un valor tan extremo como el observado</strong>, bajo el supuesto de que la <strong>hipótesis nula</strong> es verdadera, es decir, si <span class="math inline">\(\beta = 0\)</span>. Si el valor p es <strong>menor que el nivel de significancia que hayamos definido</strong> (por ejemplo, <span class="math inline">\(\alpha = 0.05\)</span>), entonces <strong>rechazamos la hipótesis nula</strong> y sostenemos que <strong>la relación lineal observada en la muestra es suficientemente fuerte como para no atribuirla al azar</strong>. En ese caso, aceptamos la posibilidad de que <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> <strong>no sean independientes</strong>.</p>
<p>La función <code>summary()</code> en R indica visualmente el nivel de significancia con asteriscos al costado de cada coeficiente: mientras más asteriscos aparecen, más pequeño es el valor p.</p>
<p><img src="images/Intercepto-4.png" class="img-fluid"></p>
<p>Cabe resaltar que esta misma conclusión también <strong>podría haberse alcanzado a partir del intervalo de confianza para</strong> <span class="math inline">\(\beta\)</span>. Como vimos anteriormente, el intervalo al 95% no incluye el valor 0, lo cual <strong>implica que los valores plausibles para la pendiente poblacional son todos negativos</strong>. En otras palabras, incluso considerando la variabilidad muestral, <strong>el efecto negativo de la distancia sobre el precio se mantiene dentro de todo el rango de valores posibles</strong> definidos por el intervalo. Por eso, tanto el contraste de hipótesis como el intervalo de confianza <strong>apuntan en la misma dirección</strong>: la relación negativa observada entre la distancia a la estación de metro y el precio por metro cuadrado <strong>es suficientemente consistente como para no atribuirla únicamente al azar</strong>.</p>
</section>
<section id="supuestos-y-calidad-de-ajuste" class="level3" data-number="8.2.3">
<h3 data-number="8.2.3" class="anchored" data-anchor-id="supuestos-y-calidad-de-ajuste"><span class="header-section-number">8.2.3</span> Supuestos y calidad de ajuste</h3>
<p>Al igual que el resto de pruebas que ya hemos visto, la regresión lineal simple también se construye sobre una serie de <strong>supuestos</strong> que nos permiten interpretar correctamente sus resultados y confiar en las conclusiones que se derivan del modelo y las pruebas que hemos realizado.</p>
<p>En primer lugar, se asume que <strong>la relación entre la variable independiente</strong> <span class="math inline">\(x\)</span> <strong>y el valor medio de la variable dependiente</strong> <span class="math inline">\(y\)</span> <strong>es lineal</strong>, es decir, que puede aproximarse razonablemente bien mediante una recta. Esto no implica que la relación real sea exactamente lineal( de hecho, rara vez lo es) sino que la línea proporciona una <strong>simplificación de la tendencia general</strong>. Por eso, <strong>antes de ajustar cualquier modelo</strong>, es importante <strong>examinarlo con un gráfico de dispersión</strong> para verificar visualmente si hay indicios de linealidad o si, por el contrario, la relación tiene una forma curva, más compleja o simplemente <strong>no hay relación alguna</strong>, lo que indicaría que los cambios en <span class="math inline">\(x\)</span> no explican las variaciones en <span class="math inline">\(y\)</span>. Sin este primer supuesto, ni siquiera tendría sentido calcular una pendiente.</p>
<p>Pero además de este supuesto de linealidad, el modelo de regresión simple reposa sobre otros <strong>supuestos estadísticos</strong>:</p>
<p>Se asume que <strong>los errores del modelo (los residuos) son independientes entre sí</strong>. Esto significa que el error cometido al estimar un valor de <span class="math inline">\(y\)</span> no debe estar relacionado con el error cometido al estimar otro.</p>
<p>Se presupone que los errores tienen <strong>varianza constante</strong> a lo largo de todos los valores de <span class="math inline">\(x\)</span>, lo que se conoce como <strong>homocedasticidad</strong>. Si los errores tienden a ser pequeños para ciertos valores de <span class="math inline">\(x\)</span> y grandes para otros (heterocedasticidad), los errores estándar de los coeficientes estarán mal calculados, y en consecuencia, <strong>los intervalos de confianza y los valores p podrían resultar engañosos</strong>.</p>
<p>Además, se asume que <strong>los errores se distribuyen normalmente</strong> alrededor de la recta de regresión. Este supuesto es clave cuando queremos construir <strong>intervalos de confianza o realizar contrastes de hipótesis</strong>, ya que garantiza que los estadísticos del modelo (como la pendiente <span class="math inline">\(b\)</span>) tendrán una distribución muestral que puede ser razonablemente aproximada por una distribución <span class="math inline">\(t\)</span>. En muestras pequeñas, si los residuos son marcadamente no normales, los valores <span class="math inline">\(p\)</span> pueden no ser demasiado confiables, aunque en muestras grandes, el Teorema del Límite Central suaviza este problema.</p>
<p>Por último, como en cualquier análisis inferencial, se parte del supuesto de que <strong>los datos provienen de una muestra aleatoria representativa de la población</strong>. Si los datos están sesgados, o si hay algún mecanismo de selección que no ha sido considerado, <strong>las estimaciones pueden ser internamente coherentes pero irrelevantes a nivel poblacional</strong>. En ese caso, cualquier generalización que se haga desde la muestra al conjunto más amplio será injustificada y poco realista, algo que por momento se olvida.</p>
<p>Todos estos supuestos están profundamente entrelazados con <strong>la validez del modelo</strong> y la <strong>fiabilidad de las inferencias que realizamos a partir de él</strong>. Y aunque se suelen presentar por separado, en la práctica los analizamos a través de un mismo enfoque: <strong>el estudio del comportamiento de los residuos</strong>.</p>
<p>Recuerda que los residuos son las partes de la relación que el modelo no ha podido capturar. Si los residuos muestran patrones sistemáticos, acumulaciones, variaciones anómalas o comportamientos extremos, eso indica que el modelo está <strong>dejando aspectos importantes sin capturar</strong>, lo que pone en cuestión la validez de los coeficientes estimados y de cualquier inferencia que se derive del modelo.</p>
<p>Por eso, <strong>el análisis de residuos es una herramienta clave de diagnóstico</strong>, y en regresión lineal existen cuatro gráficos principales que nos permiten inspeccionarlos desde distintos ángulos:</p>
<ol type="1">
<li><strong>Residuals vs Fitted</strong><br>
Este gráfico nos permite evaluar la <strong>validez del supuesto de linealidad</strong>. Si el modelo es adecuado, deberíamos observar una <strong>nube de puntos dispersa alrededor de la línea horizontal en cero</strong>, sin patrones definidos. Ondas, curvas o estructuras indican que el modelo lineal no está capturando adecuadamente la forma real de la relación entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
<p>Podemos ver que, en el caso de nuestro modelo para las viviendas, aunque la nube de puntos en el gráfico <strong>Residuals vs Fitted</strong> se distribuye de forma más o menos horizontal, la línea de suavizado roja muestra una <strong>ligera curvatura</strong>, especialmente en los extremos. Esto sugiere que la relación entre la distancia al metro y el precio por metro cuadrado <strong>no es perfectamente lineal</strong>, y que el modelo tiende a <strong>ajustarse peor conforme aumentan los valores de</strong> <span class="math inline">\(x\)</span>.</p>
<ol start="2" type="1">
<li><strong>Normal Q-Q Plot</strong><br>
Aquí examinamos si los residuos siguen una distribución aproximadamente normal, como lo requiere la inferencia basada en mínimos cuadrados. Si los residuos <strong>se alinean con la línea diagonal</strong>, el supuesto de normalidad es razonable. Desviaciones sistemáticas (especialmente en los extremos) pueden señalar asimetría, colas pesadas o valores atípicos. El eje <span class="math inline">\(y\)</span> representa ambos extremos de la distribución en desviaicones estándar.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo, <span class="at">which =</span> <span class="dv">2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
<p>Para nuestro modelo, la mayor parte de los puntos siguen bien la línea diagonal, lo que sugiere una distribución aproximadamente normal. Sin embargo, en los extremos (colas) hay algunas desviaciones, especialmente por encima del percentil 95.</p>
<ol start="3" type="1">
<li><strong>Scale-Location (Spread-Location)</strong><br>
Este gráfico nos ayuda a verificar el supuesto de <strong>homocedasticidad</strong>, es decir, que la varianza de los errores sea constante para todos los valores ajustados. En un modelo bien especificado, deberíamos ver los puntos <strong>distribuidos de forma pareja</strong> a lo largo de la línea horizontal. Si en cambio se observa una forma de embudo (estrecho al inicio y abierto al final o viceversa), es una señal clara de <strong>heterocedasticidad</strong>.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo, <span class="at">which =</span> <span class="dv">3</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
<p>Para nuestro modelo, la dispersión de los puntos aumenta ligeramente con los valores ajustados: los residuos son más pequeños cuando el valor ajustado es bajo, y más grandes a medida que se incrementa. Esto sugiere una posible heterocedasticidad leve.</p>
<ol start="4" type="1">
<li><strong>Residuals vs Leverage</strong><br>
El gráfico <strong>Residuals vs Leverage</strong> nos permite identificar <strong>observaciones que podrían estar influyendo desproporcionadamente en el ajuste del modelo</strong>, es decir, puntos que no solo están alejados del centro de los datos en el eje <span class="math inline">\(x\)</span> (alto <em>leverage</em>), sino que además presentan residuos grandes. Estos casos son importantes porque, por su ubicación y comportamiento, <strong>tienen mayor capacidad de “empujar” o inclinar la recta de regresión hacia sí mismos</strong> en detrimento de las demás observaciones, afectando la estimación de los coeficientes. No todo punto con alto <em>leverage</em> es problemático, pero cuando se combina con un residuo elevado, conviene prestar atención: <strong>puede estar distorsionando el modelo más de lo que parece</strong>. En este gráfico, las líneas punteadas indican valores de referencia según la <em>Cook’s distance</em>, que ayuda a identificar esos puntos influyentes. Si alguna observación cae cerca o por encima de esas curvas, es recomendable revisarla con más detalle, no necesariamente para eliminarla, sino para entender <strong>por qué se comporta de forma tan distinta al resto</strong> y qué impacto tiene sobre el modelo.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo, <span class="at">which =</span> <span class="dv">5</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
<p>Para nuestro modelo vemos algunos puntos etiquetados (como 271, 149 y 2500) que tienen mayor leverage y residuos relativamente grandes, lo que sugiere que podrían estar influyendo en los coeficientes del modelo. Sin embargo, ninguno parece extremadamente fuera de rango en cuanto a distancia de Cook (curvas punteadas).</p>
<p>Podemos evaluarlo individualmente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculamos Cook's Distance y lo añadimos al dataset</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>casas_cook <span class="ot">=</span> casas <span class="sc">%&gt;%</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cooks_distance =</span> <span class="fu">cooks.distance</span>(modelo))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Vemos las observaciones influyentes</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>casas_cook <span class="sc">%&gt;%</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(cooks_distance)) <span class="sc">%&gt;%</span> </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">5</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 5
  dist_to_mrt_m n_convenience house_age_years price_twd_msq cooks_distance
          &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;          &lt;dbl&gt;
1          253.             1 0 to 15                 35.6          0.0929
2         6306.             1 15 to 30                 4.54         0.0529
3         3781.             0 15 to 30                13.6          0.0487
4         6396.             1 30 to 45                 3.69         0.0402
5         6488.             1 15 to 30                 3.39         0.0395</code></pre>
</div>
</div>
<p>Podemos verlo visualmente</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Normalmente vemos las cuatro en conjunto para poder hacernos una idea general del desempeño del ajuste:</p>
<div class="cell" data-rig.width="8">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajusta los graficos 2x2</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Los cuatro gráficos de diagnóstico nos muestran que, para este modelo ajustado con los datos de viviendas, <strong>la relación lineal es razonable pero no perfecta</strong>. En conjunto, el modelo resulta útil para describir la tendencia general y realizar inferencias básicas, aunque si quisieramos <strong>mejorar la precisión del ajuste y la estabilidad de los errores estándar, sería recomendable considerar transformaciones o incorporar variables adicionales que expliquen mejor la variabilidad observada en los extremos</strong>.</p>
<p>Todas estas evaluaciones permiten <strong>entender las limitaciones del modelo, detectar posibles errores de especificación</strong> y son sumamente importantes. Ignorar esta etapa sería asumir que el modelo es correcto solo porque produce coeficientes y valores p, lo cual propondría un error metodológico grave.</p>
</section>
</section>
<section id="regresión-múltiple" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="regresión-múltiple"><span class="header-section-number">8.3</span> Regresión múltiple</h2>
<p>Como vimos, la regresión lineal simple busca ajustar un modelo lineal que describa la relación entre una variable respuesta cuantitativa y una sola variable explicativa. Sin embargo, en muchos casos, especialmente en ciencias sociales, esta relación no puede entenderse de forma aislada. La realidad suele estar influida por múltiples factores al mismo tiempo, por lo que se vuelve necesario ampliar el enfoque e incorporar más de una variable explicativa. Esto puede responder a razones teóricas, cuando distintas variables son relevantes para explicar un fenómeno, o a motivaciones analíticas, como explorar mejor la estructura de los datos o evitar interpretaciones sesgadas por omisión de variables importantes.</p>
<p>Cuando establecemos un modelo de regresión con más de una variable explicativa, hablamos de una regresión lineal múltiple. En este tipo de modelos seguimos asumiendo que existe una relación lineal, es decir, de variación proporcional, entre cada variable explicativa y la respuesta <span class="math inline">\(y\)</span>, aunque ahora la línea se transforma en un plano o hiperplano, dependiendo del número de predictores. A diferencia del modelo simple, en la regresión múltiple ya no buscamos entender el efecto de una sola variable sobre <span class="math inline">\(y\)</span>, sino cómo varias variables, en conjunto, contribuyen a explicar su comportamiento.</p>
<p>La representación gráfica del modelo múltiple no es tan directa. Más allá de tres variables, no podemos visualizar de forma intuitiva el espacio geométrico del modelo, por lo que el análisis visual se vuelve más abstracto y la atención se centra en la interpretación de sus coeficientes.</p>
<div class="cell" data-rig.width="8">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Sabemos que en muchos fenómenos del mundo real, y con aún mayor énfasis en las ciencias sociales, una sola variable rara vez es suficiente para capturar la complejidad de un fenómeno. Por ejemplo, el precio de una vivienda puede depender de su cercanía al metro, pero también del tamaño, el número de habitaciones, el estado de conservación, la ubicación, entre otros factores. Un caso similar se da en estudios sobre rendimiento educativo, donde no basta con analizar solo el nivel socioeconómico del estudiante. También influyen variables como el tipo de colegio, el capital cultural del hogar, la calidad de los docentes, la carga horaria y el acceso a recursos extracurriculares.</p>
<p>Desde una perspectiva más general, al pasar de un modelo simple a uno múltiple, transitamos de una lógica unidimensional a una lógica multivariable, en la que la variable respuesta se modela como una función lineal de varios predictores. Esto amplía las posibilidades del análisis, pero también introduce nuevos desafíos en término de su interpretación con los coeficientes y la necesidad de verificar supuestos adicionales. Incluir más variables permite construir un modelo que refleje la dinámica del fenómeno de una forma más realista. Y si bien, generalmente mejora también su capacidad explicativa, muchas veces tampoco de garante de un mejor modelo por lo que tendremos que ser cuidadosos.</p>
<section id="modelo-de-regresión-múltiple" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="modelo-de-regresión-múltiple"><span class="header-section-number">8.3.1</span> Modelo de regresión múltiple</h3>
<p>Y entonces, ¿qué hay de la ecuación del modelo? Si ya entendimos cómo funciona la regresión lineal simple, ahora toca ver cómo se generaliza cuando agregamos más de una variable explicativa.</p>
<p>En la regresión simple trabajamos con dos parámetros clave: el intercepto (<span class="math inline">\(\alpha\)</span>) y la pendiente (<span class="math inline">\(\beta\)</span>), donde <span class="math inline">\(\beta\)</span> representaba el <strong>cambio promedio en la variable respuesta</strong> <span class="math inline">\(y\)</span> <strong>por cada unidad adicional en la variable explicativa</strong> <span class="math inline">\(x\)</span>. La regresión múltiple toma esta lógica básica y la extiende, permitiéndonos incluir <strong>varias variables explicativas a la vez</strong>. Desde el punto de vista metodológico, esto significa que <strong>ya no estamos observando una relación aislada entre dos variables, sino que queremos entender cómo un conjunto de predictores contribuyen en conjunto a explicar la variación en</strong> <span class="math inline">\(y\)</span>.</p>
<p>Este modelo se expresa de la siguiente manera:</p>
<p><span class="math display">\[
y_i = \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \dots + \beta_p x_{pi}
\]</span></p>
<p>donde: - <span class="math inline">\(y_i\)</span> es el valor observado de la variable respuesta para la observación <span class="math inline">\(i\)</span>, - <span class="math inline">\(x_{1i}, x_{2i}, \dots, x_{pi}\)</span> son los valores de las <span class="math inline">\(p\)</span> variables explicativas en esa observación, - <span class="math inline">\(\alpha\)</span> es el intercepto, que representa el valor esperado de <span class="math inline">\(y\)</span> cuando todas las variables explicativas valen cero.</p>
<p>Ahora bien, lo interesante de esta versión del modelo no es solo que agregamos más variables, sino que <strong>los parámetros adquieren un nuevo sentido</strong>. En la regresión simple, la pendiente <span class="math inline">\(\beta\)</span> representaba el efecto total de <span class="math inline">\(x\)</span> sobre <span class="math inline">\(y\)</span>. Pero en este caso, <strong>cada</strong> <span class="math inline">\(\beta_j\)</span> representa un efecto parcial, es decir, el <strong>cambio promedio en</strong> <span class="math inline">\(y\)</span> cuando <span class="math inline">\(x_j\)</span> varía una unidad, manteniendo constantes todas las demás variables del modelo.</p>
<p>Este matriz cambia por completo la lógica interpretativa: ya no estamos leyendo relaciones directas, sino <strong>efectos condicionados</strong>, donde cada coeficiente nos dice qué aporta esa variable <em>por sí sola</em>, en el contexto del resto. Es por eso que, en regresión múltiple, <strong>la interpretación debe hacerse con más cautela</strong>, y debemos considerar cómo interactúan y se correlacionan las variables entre sí. Los coeficientes siguen siendo pendientes, sí, pero ahora <strong>pendientes parciales</strong>, que solo pueden leerse correctamente entendiendo el entorno estadístico en el que están estimadas.</p>
<p>En R, ajustar un modelo de regresión lineal múltiple es tan sencillo como en el caso simple. La función <code>lm()</code> se utiliza de la misma manera, pero ahora incluimos más de una variable explicativa en la fórmula. Por ejemplo, si quisieramos queremos modelar el precio por metro cuadrado (<code>price_twd_msq</code>) como una función de la <strong>distancia a la estación de metro</strong> (<code>dist_to_mrt_m</code>) y ahora también del <strong>número de tiendas de conveniencia cercanas</strong> (<code>n_convenience</code>). El código sería el siguiente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>modelo_multiple <span class="ot">=</span> <span class="fu">lm</span>(price_twd_msq <span class="sc">~</span> dist_to_mrt_m <span class="sc">+</span> n_convenience, </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> casas)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_multiple)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = price_twd_msq ~ dist_to_mrt_m + n_convenience, data = casas)

Residuals:
     Min       1Q   Median       3Q      Max 
-11.0484  -1.7736  -0.4108   1.4468  23.7786 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   11.837490   0.393194  30.106  &lt; 2e-16 ***
dist_to_mrt_m -0.001688   0.000143 -11.799  &lt; 2e-16 ***
n_convenience  0.362360   0.061291   5.912 7.11e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.928 on 411 degrees of freedom
Multiple R-squared:  0.4966,    Adjusted R-squared:  0.4941 
F-statistic: 202.7 on 2 and 411 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Este modelo nos permite estimar los efectos <strong>condicionales</strong> de cada variable sobre el precio. Es decir, evalúa <strong>qué ocurre con el precio si una de las variables cambia una unidad, mientras que la otra se mantiene constante</strong>.</p>
<p>La función <code>summary()</code> nos da un resumen completo del modelo ajustado. Dentro de este resumen, los elementos clave son:</p>
<ul>
<li><p><strong>Estimate</strong>: estos son los valores estimados de los coeficientes del modelo (<span class="math inline">\(\hat\beta_j\)</span>). Cada uno representa una <strong>pendiente parcial</strong>, es decir, el cambio promedio en el precio por metro cuadrado cuando esa variable aumenta una unidad, <strong>manteniendo constante la otra variable</strong>.</p></li>
<li><p><strong>Std. Error</strong>: error estándar de cada estimación, que nos da una idea de la precisión con la que fue calculado el coeficiente.</p></li>
<li><p><strong>t value</strong>: estadístico <span class="math inline">\(t\)</span> para contrastar la hipótesis nula de que el coeficiente es igual a cero. Cuanto mayor sea este valor en valor absoluto, más evidencia hay en contra de la hipótesis nula.</p></li>
<li><p><strong>Pr(&gt;|t|)</strong>: valor <span class="math inline">\(p\)</span> asociado a ese test. Si es menor que 0.05 (u otro umbral que definamos), interpretamos que <strong>el coeficiente es estadísticamente distinto de cero</strong>.</p></li>
<li><p><strong>Residual standard error</strong>: desviación estándar de los residuos, que nos da una medida de cuánto se desvían, en promedio, las observaciones reales del valor ajustado por el modelo.</p></li>
<li><p><strong>Multiple R-squared</strong>: proporción de la variabilidad total de <span class="math inline">\(y\)</span> que el modelo logra explicar con todos los predictores.</p></li>
<li><p><strong>Adjusted R-squared</strong>: versión ajustada del anterior que penaliza por el número de variables incluidas. Es más realista cuando se comparan modelos con diferente cantidad de predictores (más sobre esto mas adelante).</p></li>
</ul>
<p>Al observar los coeficientes estimados, vemos cómo la distancia al metro y el número de tiendas explican el precio no de forma aislada, sino <strong>en el contexto del efecto de la otra</strong>. Por ejemplo, si el coeficiente de <code>dist_to_mrt_m</code> es negativo, eso nos dice que <strong>a igual número de tiendas cercanas</strong>, un aumento en la distancia se asocia con una reducción en el precio. Lo mismo ocurre con <code>n_convenience</code>: si su coeficiente es positivo, eso significa que <strong>manteniendo fija la distancia al metro</strong>, más tiendas cercanas tienden a estar asociadas con precios más altos.</p>
<p>Así, el modelo múltiple no solo mejora la capacidad explicativa, sino que <strong>nos obliga a repensar la interpretación</strong>. Ya no estamos describiendo relaciones simples, sino <strong>efectos marginales</strong>, que solo cobran sentido cuando entendemos qué otras variables están siendo controladas en simultáneo.</p>
<p>Una forma clara de ver este cambio es <strong>comparar los coeficientes estimados en el modelo simple y en el múltiple</strong>. En particular, podemos observar cómo se modifica la pendiente de <code>dist_to_mrt_m</code> al introducir el número de tiendas como variable de control.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>modelo<span class="sc">$</span>coefficients</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept) dist_to_mrt_m 
 13.873351606  -0.002197292 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>modelo_multiple<span class="sc">$</span>coefficients</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept) dist_to_mrt_m n_convenience 
 11.837489468  -0.001687748   0.362359771 </code></pre>
</div>
</div>
<p>En el modelo simple, la pendiente estimada para <code>dist_to_mrt_m</code> era de aproximadamente <strong>–0.0022</strong>, lo que implicaba que, por cada metro adicional de distancia al metro, el precio disminuía en promedio 0.0022 unidades. Sin embargo, al introducir <code>n_convenience</code> como variable explicativa, la pendiente se reduce en magnitud a <strong>–0.0017</strong>.</p>
<p>Este cambio se puede interpretar de la siguiente forma: <strong>parte del efecto que atribuíamos originalmente a la distancia estaba en realidad capturando también el efecto de la densidad de tiendas</strong>. Es decir, al no controlar por <code>n_convenience</code>, el modelo estaba sobreestimando el impacto de <code>dist_to_mrt_m</code>. Una vez que incluimos ambas variables, el modelo “redistribuye” la varianza explicada, asignando a cada predictor <strong>su contribución parcial real</strong>.</p>
<p>Por otro lado, el coeficiente de <code>n_convenience</code> es positivo (0.36), lo que sugiere que, manteniendo constante la distancia al metro, <strong>una tienda adicional en el entorno está asociada en promedio con un aumento de 0.36 unidades en el precio por metro cuadrado</strong>. Esto refuerza la intuición que podemos tener: <strong>no solo importa qué tan cerca está una vivienda del transporte público, sino también qué servicios la rodean</strong>.</p>
</section>
<section id="control-de-variables" class="level3" data-number="8.3.2">
<h3 data-number="8.3.2" class="anchored" data-anchor-id="control-de-variables"><span class="header-section-number">8.3.2</span> Control de variables</h3>
<p>Uno de los aportes más importantes de la regresión múltiple es que <strong>nos permite controlar por otras variables al analizar la relación entre dos variables específicas</strong>. Pero, ¿qué significa exactamente “controlar por”? En términos simples, quiere decir que <strong>estamos estimando el efecto de una variable explicativa sobre la variable respuesta, mientras mantenemos constantes las demás</strong>. Este matiz es fundamental, porque en muchos casos, si no controlamos por variables relevantes, <strong>la estimación que obtenemos puede estar sesgada</strong>, ya sea por una relación espuria o por la omisión de un factor que en realidad está explicando parte del patrón observado.</p>
<p>Desde una perspectiva práctica, lo que hacemos al incluir una variable en el modelo no es simplemente añadir información, sino <strong>aislar la parte de la variación en</strong> <span class="math inline">\(y\)</span> que se asocia exclusivamente con una de las variables explicativas, neta del efecto de las demás. En vez de preguntarnos simplemente “¿qué tan fuerte es la relación entre <span class="math inline">\(x_1\)</span> e <span class="math inline">\(y\)</span>?”, lo que preguntamos es: “¿qué tan fuerte es esa relación <strong>una vez que ya hemos tomado en cuenta</strong> lo que explican <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span> y demás?”.</p>
<p>Este tipo de razonamiento es crucial en contextos donde las variables explicativas están correlacionadas entre sí. Por ejemplo, en estudios sobre participación electoral, podríamos observar que las personas mayores tienden a votar más que las personas jóvenes. Sin embargo, si no controlamos por variables como el nivel educativo, el interés político o el acceso a información, podríamos <strong>atribuir a la edad un efecto que en realidad está mediado por otros factores</strong>. Al incorporar esas variables en un modelo de regresión múltiple, podemos distinguir si la edad tiene un efecto directo sobre la propensión a votar o si su efecto está condicionado por la formación, la socialización política o el contexto institucional. En ese sentido, <strong>el control de variables permite aislar el efecto específico de un factor dentro de un fenómeno que, en la práctica, es multidimensional</strong>.</p>
<p>Otro ejemplo aparece en el análisis del mercado inmobiliario. Supongamos que queremos estimar el efecto del número de baños sobre el precio de una vivienda. Si usamos una regresión simple, podríamos encontrar una relación positiva: más baños, mayor precio. Sin embargo, las viviendas con más baños también suelen tener más metros cuadrados, mejor ubicación y otras características que contribuyen al valor final. Al incluir <strong>los metros cuadrados como variable de control</strong>, lo que estimamos ahora es el efecto de los baños <strong>manteniendo constante el tamaño de la vivienda</strong>. En ese contexto, el signo del coeficiente puede incluso invertirse: podría ocurrir que, entre dos viviendas del mismo tamaño, la que tiene más baños sea percibida como mal distribuida o incómoda. En ese caso, <strong>la relación entre número de baños y precio puede pasar de positiva a negativa al controlar por otra variable clave</strong>, lo que se conoce como <strong>una paradoja de Simpson</strong>. Este fenómeno ocurre cuando <strong>la relación observada a nivel general se revierte al examinarla dentro de subgrupos homogéneos</strong> o al ajustar por una variable relevante que estaba oculta en el análisis simple.</p>
<p>Desde el punto de vista matemático, el control ocurre automáticamente al incluir la variable en el modelo. No es que fijamos su valor manualmente como en un experimento, sino que la regresión <strong>estima los coeficientes ajustando simultáneamente el aporte de cada variable</strong>, teniendo en cuenta su contribución marginal una vez descontado lo que explican las demás. Así, cada <span class="math inline">\(\beta_j\)</span> se interpreta como el cambio esperado en <span class="math inline">\(y\)</span> ante un cambio de una unidad en <span class="math inline">\(x_j\)</span>, <strong>manteniendo constantes todas las demás variables del modelo</strong>.</p>
<p>Para ilustrar esto gráficamente, regresemos a lo más básico: el ajuste de una <strong>regresión lineal simple</strong> que modela el precio por metro cuadrado en función únicamente de la distancia a la estación de metro. Este gráfico nos permite ver la relación promedio entre ambas variables, y cómo el modelo intenta sintetizar esa relación mediante una línea recta.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>casas <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> dist_to_mrt_m, <span class="at">y =</span> price_twd_msq)) <span class="sc">+</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">'darkblue'</span>) <span class="sc">+</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">'lm'</span>, <span class="at">se =</span> F, <span class="at">color =</span> <span class="st">'gray20'</span>) <span class="sc">+</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Relación entre distancia al Metro y precio por metro cuadrado"</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Distancia a la estación de metro (m)"</span>,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Precio por m² (TWD)"</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()  </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Esta visualización nos ofrece un primer vistazo a cómo varía el precio en función de la cercanía al metro. Sin embargo, como ya mencionamos, <strong>este modelo está capturando no solo el efecto de la distancia</strong>, sino también todo lo que no hemos incluido en el análisis: características del vecindario, servicios, edad del inmueble, etc. Una de esas variables potencialmente importantes es el número de tiendas de conveniencia cercanas, que podría estar asociada tanto a la distancia como al precio.</p>
<p>Para comenzar a <strong>visualizar el efecto conjunto de ambas variables</strong>, podemos mantener el mismo gráfico base, pero ahora <strong>coloreando los puntos según el número de tiendas cercanas</strong>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>casas <span class="sc">%&gt;%</span> </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> dist_to_mrt_m, <span class="at">y =</span> price_twd_msq, </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">color =</span> n_convenience)) <span class="sc">+</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"gray20"</span>) <span class="sc">+</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_c</span>(<span class="at">option =</span> <span class="st">"D"</span>, <span class="at">direction =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Controlando por número de tiendas cercanas"</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Distancia a la estación de metro (m)"</span>,</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Precio por m² (TWD)"</span>,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">"Tiendas cercanas"</span>) <span class="sc">+</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>,</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">9</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Una observación importante que surge al visualizar nuestros datos es que <strong>la distancia a la estación de metro y el número de tiendas cercanas no son independientes entre sí</strong>. Más bien, tienden a ir en la misma dirección: a medida que las viviendas se ubican más cerca del metro, también suelen estar rodeadas de una mayor cantidad de tiendas de conveniencia. Comprender esta lógica es fundamental para interpretar correctamente los resultados y para diseñar modelos sólidos. No controlar por ciertas variables puede llevarnos a <strong>sobreestimar o subestimar efectos</strong>, o incluso a encontrar relaciones que se revierten cuando se incorpora más información.</p>
<p>Pero cuidado, cuando decidimos controlar por una variable, <strong>no basta con incluirla automáticamente en el modelo</strong>. También es necesario preguntarnos <strong>cómo se relaciona con las demás variables explicativas</strong>. Si dos predictores van en la misma dirección, como ocurre aquí entre la distancia al metro y el número de tiendas, debemos evaluar con cuidado <strong>cuán fuerte es esa asociación</strong>, porque a partir de cierto punto puede generar <strong>multicolinealidad</strong>. Y esto no es un error del modelo, pero <strong>sí un riesgo para la interpretación de los coeficientes</strong>: lo que parecía un efecto claro en un modelo simple puede diluirse, invertirse o volverse inestable cuando lo analizamos dentro de un sistema más complejo.</p>
</section>
<section id="evaluando-multicolinealidad" class="level3" data-number="8.3.3">
<h3 data-number="8.3.3" class="anchored" data-anchor-id="evaluando-multicolinealidad"><span class="header-section-number">8.3.3</span> Evaluando multicolinealidad</h3>
<p>Antes de pasar al modelo formal, conviene retomar brevemente lo que observamos en la visualización anterior. En ese gráfico, modelamos la relación entre el precio por metro cuadrado y la distancia a la estación de metro, <strong>coloreando los puntos según el número de tiendas cercanas</strong>. A través de ese recurso visual, ya habíamos notado que las dos variables explicativas (la distancia al metro y la densidad de tiendas) <strong>parecían ir en la misma dirección</strong>: a menor distancia, mayor número de tiendas.</p>
<p>Esta asociación empírica es coherente con lo que esperaríamos en el contexto urbano, pero también nos plantea una pregunta importante al momento de ajustar el modelo: <strong>¿cómo se comportan estas dos variables cuando se incluyen simultáneamente como predictores?</strong> En particular, ¿están aportando información independiente, o están explicando aspectos similares del fenómeno?</p>
<p>Cuando decidimos controlar por más de una variable en un modelo de regresión múltiple, estamos asumiendo que el modelo puede distinguir con claridad el efecto que aporta cada predictor. Sin embargo, si las variables explicativas están demasiado relacionadas entre sí, esa claridad comienza a desdibujarse. Es lo que se conoce como <strong>multicolinealidad</strong>, una situación en la que el modelo funciona (ajusta, calcula, predice), pero donde la interpretación de los coeficientes <strong>pierde precisión y estabilidad</strong>. En otras palabras, los coeficientes siguen existiendo, pero ya no está tan claro qué están midiendo realmente.</p>
<p>Una primera forma de aproximarse a esta pregunta es a través de una <strong>matriz de correlación</strong>. En nuestro caso, seleccionamos las variables predictoras del modelo (la distancia a la estación de metro y el número de tiendas cercanas) y calculamos su correlación de Pearson. Esto nos permite observar de forma sencilla <strong>la fuerza y dirección de la relación lineal entre ellos</strong>, y anticipar si existe redundancia en la información explicativa.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrr)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>casas <span class="sc">%&gt;%</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(dist_to_mrt_m, n_convenience) <span class="sc">%&gt;%</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">correlate</span>() </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  term          dist_to_mrt_m n_convenience
  &lt;chr&gt;                 &lt;dbl&gt;         &lt;dbl&gt;
1 dist_to_mrt_m        NA            -0.603
2 n_convenience        -0.603        NA    </code></pre>
</div>
</div>
<p>Aunque esta herramienta no capta relaciones multivariadas, sí ofrece un primer vistazo útil. Si la correlación es moderada o alta (por ejemplo, mayor a 0.6). Por ejemplo, en nuestro caso obtenemos un coeficiente de <strong>–0.60 entre la distancia al metro y el número de tiendas cercanas</strong>. Este valor nos dice dos cosas importantes. Primero, que <strong>la relación es inversa</strong>: a medida que una vivienda se ubica más lejos del metro, <strong>tiende a tener menos tiendas en sus alrededores</strong>. Segundo, que <strong>esa relación no es débil</strong>: un valor de –0.60 en términos de correlación lineal ya indica una conexión estructural relativamente fuerte entre ambas variables.</p>
<p>Podemos visualizarlo en un mapa de calor con <code>dlookr</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dlookr)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>casas <span class="sc">%&gt;%</span> </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(dist_to_mrt_m, n_convenience) <span class="sc">%&gt;%</span> </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_correlate</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Esto no es sorprendente desde el punto de vista urbano. Las zonas más céntricas y conectadas (cerca del transporte público) suelen estar más densamente equipadas en servicios. Pero desde el punto de vista del modelo, este resultado <strong>nos pone en alerta</strong>: si ambas variables explicativas se mueven juntas de forma consistente, el modelo tendrá más dificultad para separar sus efectos individuales.</p>
<p>Este es precisamente el tipo de escenario donde <strong>controlar por una variable exige también diagnosticar su relación con las demás</strong>. Si no lo hacemos, corremos el riesgo de interpretar como efecto propio lo que en realidad es un <strong>efecto compartido</strong>. En este caso, si no incluimos las dos variables con cuidado o no evaluamos su interacción, podríamos estar <strong>sobrecargando a una con parte del efecto de la otra</strong>, y eso distorsionaría por completo la lectura de los coeficientes.</p>
<p>Una vez observada la correlación entre predictores, el siguiente paso es <strong>confirmar formalmente si esa relación está afectando la estabilidad del modelo</strong>. Para eso utilizamos el <strong>VIF (Variance Inflation Factor)</strong>, que nos indica cuánto se ve inflada la varianza del estimador de cada coeficiente debido a su correlación con los demás predictores.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(modelo_multiple)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dist_to_mrt_m n_convenience 
     1.569931      1.569931 </code></pre>
</div>
</div>
<p>Lo primero que notamos es que ambos predictores tienen exactamente el mismo valor de VIF. Esto tiene sentido, ya que vimos que su correlación es simétrica y lineal. Y lo segundo, y más importante, es que <strong>el valor está muy por debajo de los umbrales críticos comúnmente utilizados</strong>. En general, un VIF cercano a 1 indica ausencia de colinealidad, y se empieza a considerar preocupante solo cuando supera 5 (y especialmente 10).</p>
<p>Entonces, ¿qué nos dice este resultado? Que <strong>aunque existe una relación lineal moderada entre distancia y tiendas</strong>, <strong>no es lo suficientemente fuerte como para causar inflación significativa en la varianza de los coeficientes</strong>. En otras palabras, el modelo logra diferenciar ambos efectos de manera estadísticamente aceptable, y podemos interpretarlos sin una alerta roja por colinealidad.</p>
<p>Ahora bien, esto no significa que debamos ignorar la relación entre ellos. La correlación sigue existiendo, y sigue siendo importante para entender <strong>cómo se distribuye la varianza explicada en el modelo</strong>. Lo que el VIF nos asegura es que <strong>esa relación no está comprometiendo la precisión de nuestras estimaciones</strong>.</p>
<p>Por eso es tan importante complementar la exploración visual y la matriz de correlación con un diagnóstico más robusto. Un valor de VIF bajo no niega la existencia de correlación, pero nos indica que <strong>esa correlación no está impidiendo que el modelo funcione como debe</strong>. Y en este caso, eso nos permite avanzar con mayor confianza en la interpretación de los coeficientes estimados.</p>
<p>Evaluar la multicolinealidad no es una formalidad técnica, sino parte del proceso de asegurarnos que <strong>las interpretaciones que extraemos del modelo son válidas y estables</strong>. Si las variables explicativas están correlacionadas, el modelo puede seguir ajustándose bien, pero las inferencias sobre el efecto de cada predictor <strong>deben leerse como efectos condicionales</strong>, es decir, suponiendo que las demás variables se mantienen constantes.</p>
<p>En nuestro caso, aunque no se observa una colinealidad excesiva, el análisis nos recuerda que <strong>las variables urbanas suelen estar interrelacionadas</strong>, y que esa interdependencia debe ser tenida en cuenta no solo en el ajuste del modelo, sino también en la lectura crítica de sus resultados.</p>
</section>
<section id="r2-en-la-correlación-múltiple" class="level3" data-number="8.3.4">
<h3 data-number="8.3.4" class="anchored" data-anchor-id="r2-en-la-correlación-múltiple"><span class="header-section-number">8.3.4</span> R2 en la correlación múltiple</h3>
<p>Hasta ahora hemos evaluado cómo se comportan individualmente las variables explicativas, qué aportan por sí solas y cómo se relacionan entre sí. Sin embargo, cuando construimos modelos de regresión múltiple, <strong>lo que realmente queremos saber no es solo qué efecto tiene cada variable, sino cuánto mejora el modelo al incluirlas</strong>. En otras palabras: <strong>¿vale la pena añadir una variable más? ¿Estamos explicando mejor el fenómeno o solo estamos complicando el modelo?</strong></p>
<p>Aquí entra en juego el coeficiente de determinación, el ya conocido <span class="math inline">\(R^2\)</span>, que vimos en el caso de la regresión simple, pero que cobra <strong>un nuevo sentido</strong> en el contexto múltiple. Recordemos que <span class="math inline">\(R^2\)</span> mide la proporción de la varianza total de la variable respuesta que el modelo logra explicar con sus predictores. Cuanto más cerca esté de 1, mejor será el ajuste. Pero a diferencia del caso simple, <strong>en los modelos con múltiples variables</strong> <span class="math inline">\(R^2\)</span> siempre tiende a subir, aunque la nueva variable no aporte nada sustancial.</p>
<p>Por eso, cuando trabajamos con regresión múltiple, no basta con mirar el <span class="math inline">\(R^2\)</span> “a secas”. Debemos mirar también el <span class="math inline">\(R^2\)</span> <strong>ajustado</strong>, que penaliza la incorporación de predictores que no mejoran significativamente el modelo. Si al añadir una variable el <span class="math inline">\(R^2\)</span> aumenta, pero el <span class="math inline">\(R^2\)</span> ajustado se mantiene igual o incluso baja, eso es una señal clara de que <strong>la nueva variable no está ayudando realmente</strong>.</p>
<p>Para ver esto con datos reales, podemos comparar tres modelos:</p>
<ol type="1">
<li>Un modelo simple, con solo la distancia al metro.<br>
</li>
<li>Un modelo múltiple, que agrega el número de tiendas.<br>
</li>
<li>Un modelo más completo, que también incluye la edad de la vivienda (<code>house_age_years</code>).</li>
</ol>
<p>Aunque esta última variable es categórica,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(casas<span class="sc">$</span>house_age_years)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "30 to 45" "15 to 30" "0 to 15" </code></pre>
</div>
</div>
<p>podemos convertirla a factor para incluirla correctamente en el modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>casas <span class="ot">=</span> casas <span class="sc">%&gt;%</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">house_age_years =</span> <span class="fu">as.factor</span>(house_age_years))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Luego, ajustamos el modelo con las tres variables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>modelo_completo <span class="ot">=</span> <span class="fu">lm</span>(price_twd_msq <span class="sc">~</span> dist_to_mrt_m <span class="sc">+</span> n_convenience <span class="sc">+</span> house_age_years, </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> casas)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Y ahora observamos y comparamos sus <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2\)</span> ajustados:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)<span class="sc">$</span>r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4537543</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)<span class="sc">$</span>adj.r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4524284</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_multiple)<span class="sc">$</span>r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4965684</code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_multiple)<span class="sc">$</span>adj.r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4941186</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_completo)<span class="sc">$</span>r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5365204</code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_completo)<span class="sc">$</span>adj.r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5319876</code></pre>
</div>
</div>
<p>Con esto obtenemos una lectura clara de <strong>cuánto mejora el ajuste al incluir más variables</strong>. Si vemos que el <span class="math inline">\(R^2\)</span> crece ligeramente pero el <span class="math inline">\(R^2\)</span> ajustado no cambia o incluso cae, eso sugiere que <strong>la variable añadida está “adornando” el modelo pero no explicando realmente más</strong>. Por el contrario, si ambos crecen de manera consistente, estamos ante una variable que <strong>sí aporta a la capacidad predictiva del modelo</strong>.</p>
<p>En nuestro caso, los resultados nos permiten leer con claridad el efecto de ir agregando variables al modelo. El modelo simple, con solo la distancia al metro, logra explicar aproximadamente un <strong>45.4%</strong> de la variabilidad del precio por metro cuadrado. No es un mal punto de partida, pero sabemos que la realidad del valor de una vivienda no depende únicamente del acceso al transporte.</p>
<p>Cuando añadimos el número de tiendas cercanas, el <span class="math inline">\(R^2\)</span> sube a <strong>49.7%</strong>, y lo que es más importante, el <span class="math inline">\(R^2\)</span> ajustado también crece de forma consistente hasta <strong>49.4%</strong>. Esto nos indica que <strong>la nueva variable realmente está aportando capacidad explicativa al modelo</strong>, no solo inflando artificialmente su rendimiento. En otras palabras, tiene sentido mantenerla: no solo tiene coherencia urbana, sino que mejora la calidad del ajuste.</p>
<p>Finalmente, al incorporar la edad de la vivienda, llegamos a un <span class="math inline">\(R^2\)</span> de <strong>53.7%</strong> y un <span class="math inline">\(R^2\)</span> ajustado de <strong>53.2%</strong>. De nuevo, el crecimiento es moderado, pero consistente. No estamos forzando forzando un modelo más complejo ni cayendo en sobreajuste: estamos <strong>incorporando un factor relevante que ayuda a explicar parte de la variabilidad restante</strong>.</p>
<p>Esto confirma que cada una de las variables agregadas ha mejorado el ajuste <strong>de forma útil y justificable</strong>. No solo desde el punto de vista del modelo, sino también desde la lógica del fenómeno urbano que estamos tratando de modelar: el valor de una vivienda no depende únicamente de un factor, sino de la combinación entre ubicación, accesibilidad, servicios y características propias del inmueble. La regresión múltiple no nos da respuestas absolutas, pero sí <strong>una lectura más honesta de cómo interactúan esos factores al momento de predecir un precio</strong>.</p>
</section>
<section id="inferencia-de-coeficientes" class="level3" data-number="8.3.5">
<h3 data-number="8.3.5" class="anchored" data-anchor-id="inferencia-de-coeficientes"><span class="header-section-number">8.3.5</span> Inferencia de coeficientes</h3>
<p>Como ya vimos en la regresión lineal simple, cada coeficiente estimado en el modelo representa un <strong>valor puntual que aproxima un parámetro poblacional desconocido</strong>, y su interpretación va acompañada siempre de incertidumbre. Esa lógica no cambia cuando pasamos a un modelo múltiple. Lo que sí cambia es <strong>el contexto en el que se interpreta cada estimación</strong>.</p>
<p>En el caso del modelo completo que hemos construido, los coeficientes, incluyendo la pendiente de <code>dist_to_mrt_m</code>, el efecto de <code>n_convenience</code>, y las categorías de <code>house_age_years</code>, se entienden ahora como <strong>efectos condicionales</strong>. Es decir, no nos dicen simplemente “qué pasa cuando una variable cambia”, sino <strong>qué pasa cuando esa variable cambia mientras las demás se mantienen constantes</strong>. Y eso tiene consecuencias para la inferencia: el valor p que acompaña a cada estimación ya no está evaluando la relación “bruta” entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, sino <strong>la relación neta, dentro de un sistema de controles</strong>.</p>
<p>Por eso, aunque las pruebas estadísticas siguen siendo técnicamente las mismas (valores t, errores estándar, intervalos de confianza), su lectura cambia. Rechazar la hipótesis nula de que el coeficiente de <code>n_convenience</code> es cero, por ejemplo, no significa que más tiendas siempre aumentan el precio, sino que <strong>su efecto permanece significativo incluso cuando controlamos por distancia y edad de la vivienda</strong>. Eso le da al resultado un peso distinto, y una interpretación más robusta.</p>
<p>Además, al tratarse de un modelo con múltiples variables, <strong>los coeficientes pueden cambiar considerablemente respecto al modelo simple</strong>, no solo en magnitud sino incluso en dirección. Esto no es un error, sino una consecuencia directa del control: cuando aislamos el efecto de una variable, <strong>descubrimos lo que realmente está aportando por sí sola</strong>, y no lo que estaba heredando de su correlación con otras.</p>
<p>Ahora que hemos ajustado el modelo completo, podemos mirar en detalle lo que nos dice <code>summary(modelo_completo)</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_completo)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = price_twd_msq ~ dist_to_mrt_m + n_convenience + 
    house_age_years, data = casas)

Residuals:
    Min      1Q  Median      3Q     Max 
-11.935  -1.669  -0.444   1.312  23.088 

Coefficients:
                          Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)             12.4620937  0.3925612  31.746  &lt; 2e-16 ***
dist_to_mrt_m           -0.0015699  0.0001406 -11.168  &lt; 2e-16 ***
n_convenience            0.3982338  0.0593259   6.713 6.40e-11 ***
house_age_years15 to 30 -1.5887298  0.3290985  -4.828 1.96e-06 ***
house_age_years30 to 45 -1.7614724  0.3563492  -4.943 1.12e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.816 on 409 degrees of freedom
Multiple R-squared:  0.5365,    Adjusted R-squared:  0.532 
F-statistic: 118.4 on 4 and 409 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Comencemos por lo que ya conoces. El intercepto:</p>
<p><code>(Intercept) = 12.46</code></p>
<p>Como ya explicamos, este valor representa <strong>el precio promedio por metro cuadrado de una vivienda de entre 0 y 15 años de antigüedad</strong>, ubicada a 0 metros de una estación de metro (lo cual es hipotético,), y con cero tiendas de conveniencia cercanas (también poco realista). En modelos múltiples, el intercepto no suele tener un sentido práctico directo, pero <strong>funciona como punto de referencia</strong> a partir del cual se aplican los efectos de las otras variables.</p>
<p><code>dist_to_mrt_m = –0.00157</code></p>
<p>Este coeficiente indica que, <strong>por cada metro adicional de distancia a la estación de metro</strong>, el precio por metro cuadrado <strong>disminuye en promedio 0.00157 unidades</strong>, manteniendo constantes el número de tiendas cercanas y la edad de la vivienda. Este efecto es coherente con la intuición urbana: la accesibilidad al transporte suele ser un factor valorizador en mercados inmobiliarios densos.</p>
<p>Lo importante aquí es entender que <strong>no estamos midiendo una relación bruta</strong>, sino un efecto condicionado: incluso si dos viviendas tienen la misma edad y están rodeadas por la misma cantidad de tiendas, <strong>la que está más lejos del metro tiende a valer menos</strong>. El valor p asociado (&lt; 2e-16) indica que este efecto es altamente significativo.</p>
<p><code>n_convenience = 0.398</code></p>
<p>Este coeficiente nos dice que, <strong>por cada tienda de conveniencia adicional cercana</strong>, el precio por metro cuadrado <strong>aumenta en promedio 0.398 unidades</strong>, siempre que la distancia al metro y la antigüedad de la vivienda se mantengan constantes. En otras palabras, el efecto de las tiendas no está siendo confundido con el de la ubicación ni con el de la edad del inmueble.</p>
<p>El valor positivo confirma la idea de que <strong>los servicios de cercanía tienen un efecto valorizador</strong>, algo ya conocido en economía urbana. Pero lo que el modelo nos permite ver es que este efecto persiste <strong>independientemente del acceso al transporte</strong>.</p>
<p><code>house_age_years15 to 30 = –1.59</code></p>
<p>Aquí ingresamos al terreno de las variables categóricas. Este coeficiente no se interpreta como un precio, sino como <strong>una diferencia de precio con respecto a la categoría base</strong>, que en este caso es “0 to 15” años. Así, el valor de –1.59 nos indica que <strong>una vivienda de entre 15 y 30 años cuesta en promedio 1.59 unidades menos por metro cuadrado que una de entre 0 y 15 años</strong>, manteniendo constantes las demás variables.</p>
<p>Este efecto negativo sugiere que <strong>el valor de una vivienda se deprecia con el paso del tiempo</strong>, lo cual es esperable, sobre todo si no ha sido renovada o modernizada. Pero lo interesante es que este efecto <strong>no está asociado a peores ubicaciones o menos servicios</strong>, ya que esos elementos están controlados.</p>
<p><code>house_age_years30 to 45 = –1.76</code></p>
<p>La lógica aquí es exactamente la misma: esta estimación representa la diferencia promedio de precio entre una vivienda de entre 30 y 45 años y una de entre 0 y 15. El efecto es aún más negativo que el anterior, lo que sugiere <strong>una tendencia continua de pérdida de valor conforme avanza la antigüedad del inmueble</strong>.</p>
<p>Lo que este modelo nos está mostrando, entonces, es <strong>una curva de depreciación parcial del precio de la vivienda por edad</strong>, dentro de un contexto urbano en el que el acceso al metro y a tiendas permanece constante. Es decir, el valor no depende solo de dónde estás o qué servicios tienes cerca, <strong>sino también de cuán nuevo o viejo es el inmueble mismo</strong>.</p>
<p>Todos los valores <span class="math inline">\(p\)</span> están muy por debajo del umbral convencional de 0.05 (los asteriscos también te informan aquello), lo que significa que <strong>todos estos efectos son estadísticamente significativos</strong>. Pero, como ya hemos discutido antes, eso no quiere decir que sean “grandes” o “decisivos” por sí solos, sino que <strong>tenemos evidencia suficiente en esta muestra como para afirmar que su efecto es significativo y, por tanto, no es producto del azar</strong>.</p>
</section>
<section id="modelos-múltiples-con-interacción" class="level3" data-number="8.3.6">
<h3 data-number="8.3.6" class="anchored" data-anchor-id="modelos-múltiples-con-interacción"><span class="header-section-number">8.3.6</span> Modelos múltiples con interacción</h3>
<p>Hasta ahora, hemos trabajado con modelos múltiples que combinan varias variables explicativas para entender cómo se relacionan con una variable respuesta. En todos estos casos, el supuesto de fondo era claro: <strong>cada variable tiene un efecto independiente, que se suma a los efectos de las demás</strong>. Es lo que se conoce como <strong>modelo aditivo</strong>. Y si bien este tipo de modelos es útil y muchas veces suficiente, no siempre representa bien la complejidad de los fenómenos reales.</p>
<p>En el mundo social (y en muchos otros contextos también) <strong>los efectos rara vez son puros y aislados</strong>. Lo que una variable hace, muchas veces <strong>depende del entorno</strong>. O dicho con más precisión: <strong>el efecto de una variable puede cambiar según el valor que tome otra</strong>. Este tipo de situación es lo que en estadística se llama una <strong>interacción</strong>.</p>
<p>Entonces, ¿cómo sabemos si necesitamos modelar una interacción? A veces es una hipótesis teórica, pero muchas veces podemos verlo <strong>explorando visualmente los datos</strong>. Si trazamos una relación entre dos variables, y esa relación <strong>no tiene la misma forma o pendiente para distintos grupos</strong>, estamos frente a un caso donde <strong>el efecto de una variable cambia según otra</strong>.</p>
<p>Supongamos que estamos investigando la <strong>satisfacción de los ciudadanos con su gobierno local</strong>, medida en una escala del 1 al 10. Queremos entender cómo esta satisfacción se relaciona con el <strong>nivel de ingreso</strong> de la persona y con la <strong>zona donde reside</strong> (urbana o rural). Desde una perspectiva teórica, podríamos hipotetizar que <strong>el ingreso mejora la percepción ciudadana del gobierno</strong>, pero que <strong>ese efecto no es igual en todos los contextos</strong>.</p>
<p>Tomemos como ejemplo este conjunto de datos simulado con 200 observaciones, donde el ingreso varía entre 1000 y 5000 soles, y la zona puede ser “urbana” o “rural”.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>stf <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="st">'satisfaccion.csv'</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(stf)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 200
Columns: 4
$ ...1         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…
$ ingreso      &lt;dbl&gt; 1955, 4849, 3405, 3060, 2610, 4521, 2456, 2153, 1683, 168…
$ zona         &lt;chr&gt; "urbana", "urbana", "urbana", "rural", "urbana", "rural",…
$ satisfaccion &lt;dbl&gt; 6, 6, 4, 5, 3, 5, 4, 5, 5, 3, 6, 4, 5, 3, 3, 6, 4, 3, 3, …</code></pre>
</div>
</div>
<p>Antes de modelar, conviene graficar los los datos para ver si hay alguna pista de interacción.</p>
<p>Primero la relación global:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>stf <span class="sc">%&gt;%</span> </span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ingreso, <span class="at">y =</span> satisfaccion)) <span class="sc">+</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Relación entre ingreso y satisfacción por zona"</span>,</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Ingreso mensual (S/.)"</span>,</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Satisfacción con el gobierno local (1–10)"</span>,</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Zona de residencia"</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-41-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Ahora podemos añadir la variable <code>zona</code> diferenciando por color:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>stf <span class="sc">%&gt;%</span> </span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ingreso, <span class="at">y =</span> satisfaccion, <span class="at">color =</span> zona)) <span class="sc">+</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Relación entre ingreso y satisfacción por zona"</span>,</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Ingreso mensual (S/.)"</span>,</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Satisfacción con el gobierno local (1–10)"</span>,</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Zona de residencia"</span></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>,</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">9</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-42-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>A primera vista, <strong>parece haber una relación positiva entre ingreso y satisfacción en ambos contextos</strong>. Es decir, a medida que el ingreso aumenta, también lo hace, en promedio, la satisfacción con el gobierno local. Sin embargo, <strong>esa relación no es idéntica entre zonas</strong>. En el caso de las zonas rurales, la pendiente de la relación parece <strong>más empinada</strong>, lo que sugiere que <strong>los aumentos en ingreso tienen un mayor impacto en la percepción ciudadana</strong>. En cambio, en zonas urbanas, la relación también es positiva, pero <strong>menos pronunciada</strong>.</p>
<p>Con esa intuición visual en mente, pasamos ahora al ajuste formal de los modelos. Como hemos venido explicando, el <strong>modelo aditivo</strong> parte de la idea de que el efecto del ingreso sobre la satisfacción es <strong>el mismo para todos los grupos</strong>, en este caso, para personas de zonas urbanas y rurales. Es decir, se estima una sola pendiente común a ambos grupos, aunque se permita que el nivel promedio de satisfacción (el intercepto) <strong>sí pueda variar</strong> entre zonas.</p>
<p>Veamos cómo se ajusta este modelo en R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>modelo_aditivo <span class="ot">=</span> <span class="fu">lm</span>(satisfaccion <span class="sc">~</span> ingreso <span class="sc">+</span> zona, <span class="at">data =</span> stf)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_aditivo)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = satisfaccion ~ ingreso + zona, data = stf)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3061 -0.7584 -0.1117  0.6787  3.4160 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  3.268e+00  2.567e-01  12.730   &lt;2e-16 ***
ingreso      7.396e-04  7.395e-05  10.001   &lt;2e-16 ***
zonaurbana  -1.727e+00  1.732e-01  -9.969   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.221 on 197 degrees of freedom
Multiple R-squared:  0.5208,    Adjusted R-squared:  0.5159 
F-statistic:   107 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Es importante aclarar una idea que puede prestarse a confusión: <strong>el modelo aditivo sí toma en cuenta la variable zona</strong>, pero lo hace <strong>de una forma distinta al modelo con interacción</strong>. En el modelo aditivo, se reconoce que las personas que viven en zonas urbanas y rurales pueden tener niveles distintos de satisfacción, pero <strong>se asume que el efecto del ingreso sobre esa satisfacción es el mismo para ambos grupos</strong>.</p>
<p>Esto significa que el modelo aditivo permite <strong>diferencias en el punto de partida (el intercepto)</strong> entre zonas, pero <strong>no en la pendiente</strong>. Es decir, las líneas de regresión para zona urbana y rural pueden estar a distinta altura, pero <strong>tienen la misma inclinación</strong>. La lógica que subyace aquí es que el ingreso mejora la satisfacción al mismo ritmo sin importar el contexto, y que las diferencias entre grupos se deben solo a un nivel promedio más alto o más bajo de satisfacción.</p>
<p>En términos más concretos: si el coeficiente de ingreso en el modelo aditivo es 0.00074, entonces ese valor se aplica tanto a personas urbanas como rurales. Lo único que cambia es el valor inicial desde el cual parte esa relación. En este modelo, lo que <code>zonaurbana</code> está haciendo es ajustar el intercepto: está diciendo cuánto más (o menos) satisfechas están las personas urbanas en comparación con las rurales, <strong>cuando ingreso = 0</strong>. Pero una vez que empezamos a sumar ingreso, el efecto es el mismo para todos.</p>
<p>Aquí le estamos diciendo a R: “ajusta una recta que relacione ingreso y satisfacción, diferenciando entre zonas solo en el punto de partida (intercepto), pero manteniendo la misma pendiente para ambos grupos”.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generamos los valores ajustados del modelo aditivo</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>stf <span class="ot">=</span> stf <span class="sc">%&gt;%</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred_aditivo =</span> <span class="fu">predict</span>(modelo_aditivo))</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>stf <span class="sc">%&gt;%</span> </span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ingreso, <span class="at">y =</span> satisfaccion, <span class="at">color =</span> zona)) <span class="sc">+</span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> pred_aditivo), <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Modelo aditivo: misma pendiente, distinto intercepto"</span>,</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Ingreso mensual (S/.)"</span>,</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Satisfacción con el gobierno local"</span>,</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Zona"</span></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>,</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">9</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-44-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>El segundo modelo es más flexible. Le decimos a R que permita que <strong>la pendiente también cambie según la zona</strong>, es decir, que la relación entre ingreso y satisfacción <strong>pueda tener una forma diferente en zonas urbanas y rurales</strong>. Esto se conoce como un <strong>modelo con interacción</strong>, y se escribe añadiendo un asterisco (<code>*</code>) entre las dos variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>modelo_interaccion <span class="ot">=</span> <span class="fu">lm</span>(satisfaccion <span class="sc">~</span> ingreso <span class="sc">*</span> zona, <span class="at">data =</span> stf)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_interaccion)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = satisfaccion ~ ingreso * zona, data = stf)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.5425 -0.6968 -0.0845  0.7607  2.9174 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         2.219e+00  3.231e-01   6.866 8.49e-11 ***
ingreso             1.085e-03  9.907e-05  10.949  &lt; 2e-16 ***
zonaurbana          3.099e-01  4.452e-01   0.696    0.487    
ingreso:zonaurbana -6.882e-04  1.399e-04  -4.920 1.83e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.155 on 196 degrees of freedom
Multiple R-squared:  0.5735,    Adjusted R-squared:  0.5669 
F-statistic: 87.84 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Este modelo internamente incluye tres cosas:</p>
<ul>
<li>El efecto principal del ingreso.</li>
<li>El efecto principal de la zona (es decir, la diferencia entre urbana y rural si ingreso fuera 0).</li>
<li>La interacción: <strong>cómo cambia el efecto del ingreso dependiendo de la zona</strong>.</li>
</ul>
<p>En este modelo con interacción, lo que nos interesa principalmente es cómo cambia la <strong>relación entre ingreso y satisfacción</strong> según el tipo de zona. Y para eso, tenemos que prestar atención a dos coeficientes: <code>ingreso</code> y <code>ingreso:zonaurbana</code>.</p>
<p>El coeficiente de <code>ingreso</code> nos da la pendiente para el grupo de referencia, que en este caso es la zona rural. Su valor es aproximadamente <strong>0.001085</strong>, lo que significa que <strong>por cada 1000 soles adicionales de ingreso</strong>, la satisfacción promedio con el gobierno local <strong>aumenta en 1.085 puntos</strong> en zonas rurales. Este efecto es estadísticamente significativo, con un valor p menor a 0.001, lo cual nos indica que <strong>la relación positiva entre ingreso y satisfacción en zonas rurales es fuerte y robusta</strong>.</p>
<p>El término <code>ingreso:zonaurbana</code>, en cambio, <strong>no es una pendiente directa</strong>, sino una <strong>corrección</strong> a la pendiente anterior. Su valor es <strong>-0.000688</strong>, también estadísticamente significativo. Esto quiere decir que, en zonas urbanas, la pendiente ya no es la misma que en zonas rurales, sino que <strong>se reduce en 0.000688</strong>.</p>
<p>Para conocer la pendiente en zonas urbanas, basta con <strong>sumar ambos coeficientes</strong>:</p>
<p><span class="math display">\[
\text{Pendiente urbana} = 0.001085 - 0.000688 = 0.000397
\]</span></p>
<p>Esto implica que, para las personas que viven en zonas urbanas, un aumento de 1000 soles en el ingreso mensual <strong>solo incrementa la satisfacción en 0.397 puntos</strong>, es decir, <strong>menos de la mitad del efecto observado en zonas rurales</strong>.</p>
<p>Y esto no es menor. Ambos coeficientes son estadísticamente significativos, lo que significa que esta diferencia <strong>no puede atribuirse al azar muestral</strong>. Lo que estamos viendo aquí es un patrón claro y sostenido: <strong>el ingreso tiene un impacto más fuerte sobre la satisfacción ciudadana en zonas rurales que en zonas urbanas</strong>. Esto podría deberse a muchas razones estructurales (desigualdades en el acceso a servicios, expectativas distintas, mayor sensibilidad al cambio económico en contextos con menor infraestructura), pero lo esencial es que <strong>el modelo con interacción nos permite detectar y cuantificar esa diferencia</strong>.</p>
<p>Aquí <strong>permitimos que cada grupo tenga su propia recta</strong>, es decir, su propia relación entre ingreso y satisfacción.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(stf, <span class="fu">aes</span>(<span class="at">x =</span> ingreso, <span class="at">y =</span> satisfaccion, <span class="at">color =</span> zona)) <span class="sc">+</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Modelo con interacción: pendiente diferenciada por zona"</span>,</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Ingreso mensual (S/.)"</span>,</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Satisfacción con el gobierno local"</span>,</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Zona"</span></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>,</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">9</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regr_files/figure-html/unnamed-chunk-46-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Esta diferencia no es solo visual, tiene una implicancia estadística importante: en el modelo aditivo estamos <strong>forzando una media</strong> entre dos relaciones distintas, lo que puede resultar algo simplista. En cambio, el modelo con interacción <strong>permite que cada grupo siga su propia relación</strong>. No siempre es necesario usar interacciones, pero cuando las diferencias entre grupos son significativas, incluirlas <strong>mejora la interpretación y la precisión del análisis</strong>.</p>
</section>
</section>
<section id="un-vistazo-a-otros-modelos-de-regresión" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="un-vistazo-a-otros-modelos-de-regresión"><span class="header-section-number">8.4</span> Un vistazo a otros modelos de regresión</h2>
<p>Hasta ahora hemos trabajado con el modelo lineal clásico y sus variaciones: simple, múltiple, con interacción. Hemos aprendido a leer pendientes, interpretar interceptos y evaluar supuestos. Pero también hemos visto que este modelo funciona bajo ciertas condiciones: que la variable respuesta sea continua, que la relación con los predictores sea aproximadamente lineal, y que los errores se comporten de forma razonable. Sin embargo, cuando salimos de los ejemplos didácticos y nos enfrentamos a fenómenos reales, especialmente en las ciencias sociales, <strong>esas condiciones se tensan o directamente se rompen</strong>. Hay variables que no son continuas, sino categóricas, ordinales, proporciones, conteos. Hay relaciones que no son lineales, sino curvas o de otra naturaleza. Hay fenómenos donde los errores no son normales, y donde la media no es un bien resumen numérico del comportamiento esperado.</p>
<p>Y entonces uno se da cuenta de algo clave: <strong>el mundo de las regresiones no termina en la línea recta</strong>, sino que <strong>es un campo vasto, flexible, como la realidad misma</strong>. Lo que une a todos estos modelos es su propósito: <strong>intentar representar, con cierta estructura matemática, una relación que observamos o que queremos cuantificar</strong>. Pero el cómo se hace varía, y eso es precisamente lo que exploraremos aquí. En este apartado no voy a mostar en detalle cada técnica (que se puede aplicar en R pero el capítulo se está tornando más largo de lo esperado), pero sí voy a trazar un mapa que pueda ser de tu utilidad para investigar con mayor profundidad. Mostrar que hay otras formas de modelar, otras maneras de construir relaciones entre variables, y que la elección del modelo <strong>no es solo una cuestión técnica, sino también teórica y sustantiva</strong>: se trata de elegir el modelo que mejor captura la estructura del fenómeno que estamos estudiando.</p>
<section id="más-allá-de-la-linealidad" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="más-allá-de-la-linealidad"><span class="header-section-number">8.4.1</span> Más allá de la linealidad</h3>
<p>Una de las primeras cosas que suele fallar en la regresión clásica es la <strong>suposición de linealidad</strong>. No siempre el cambio en la variable respuesta es proporcional al cambio en la variable explicativa. Y aunque en muchos casos podemos “forzar” linealidad con transformaciones (como logaritmos o raíces cuadradas), esto tiene un costo interpretativo. Por ejemplo, si modelamos <code>log(ingreso)</code> en lugar de ingreso, la pendiente ya no se interpreta como un cambio absoluto, sino como <strong>un cambio en la variable respuesta ante un cambio porcentual en ingreso</strong>. Las transformaciones son útiles y necesarias, pero deben ser manejadas con cuidado, porque alteran el significado sustantivo del modelo. Otra opción, en lugar de transformar, s elegir <strong>otro tipo de regresión</strong> que se adapte mejor al tipo de variable o a la forma de la relación.</p>
<p><strong>Regresión logística (cuando la respuesta es binaria)</strong></p>
<p>Cuando la variable que queremos explicar <strong>no es continua, sino dicotómica</strong> (sí/no, participa/no participa, vota/no vota), la regresión lineal no es útil. Usamos la <strong>regresión logística</strong>, que modela la <strong>probabilidad</strong> de que ocurra el evento de interés a partir de una función que representa los cambios de la probabilidad. Aquí ya no hablamos de cambios en la media, sino de <strong>efectos sobre la razón de probabilidades</strong> (odds). El coeficiente de una variable nos dice cuánto se multiplican las odds de que ocurra el evento cuando esa variable aumenta una unidad, manteniendo constantes las demás. Un ejemplo clásico en ciencias sociales podría ser: ¿cuáles son las características que aumentan la probabilidad de participar de votar en elecciones municipales?</p>
<p><strong>Regresión polinómica (cuando la relación es curva)</strong></p>
<p>A veces, lo que falla no es el tipo de variable, sino su forma de relacionarse con otras. La regresión polinómica permite capturar relaciones <strong>no lineales pero suaves</strong>, introduciendo términos cuadráticos o cúbicos de una misma variable. Por ejemplo, la relación entre edad y satisfacción política no suele ser lineal: puede subir hasta cierta edad y luego bajar. En esos casos, una línea recta subestima el efecto real. Un modelo polinómico, en cambio, puede representarlo sin cambiar el tipo de variable.</p>
<p><strong>Regresión de Poisson (cuando contamos eventos)</strong></p>
<p>Hay veces en que la variable respuesta <strong>no es continua ni categórica</strong>, sino un <strong>conteo</strong>: número de asistencias, número de reuniones comunitarias, cantidad de conflictos, etc. Estos datos suelen tener una distribución asimétrica, con muchos ceros, y su varianza suele crecer con la media. La regresión de Poisson está pensada para eso. Modela el logaritmo del valor esperado de los conteos en función de los predictores. Es ampliamente usada en estudios de criminalidad, participación, salud pública y movimientos sociales.</p>
<p><strong>Regresión ordinal (cuando hay orden, pero no distancia)</strong></p>
<p>En ciencias sociales abundan las escalas de tipo Likert: de 1 a 5, de “muy en desacuerdo” a “muy de acuerdo”. Aquí las categorías tienen orden, pero no hay una distancia clara entre ellas. Una regresión lineal forzaría un supuesto que no es real (que la diferencia entre 2 y 3 es igual a la de 4 y 5).En estos casos usamos modelos <strong>logísticos ordinales</strong>, que asumen que hay un continuo subyacente (una “satisfacción latente”), y que cada categoría representa un corte en ese continuo. Así modelamos la <strong>probabilidad acumulada</strong> de estar en una categoría o inferior.</p>
<p><strong>Regresión multinomial (cuando las categorías no tienen orden)</strong></p>
<p>Hay veces en que las categorías de la variable respuesta no tienen un orden inherente: tipos de afiliación política (izquierda, centro, derecha), tipos de ocupación, regiones del país, etc. En esos casos, usamos modelos <strong>multinomiales</strong>, que comparan cada categoría con una de referencia y estiman la probabilidad relativa de estar en cada grupo.</p>
<p><strong>Modelos multinivel</strong></p>
<p>En muchos casos, los datos no vienen en observaciones individuales sueltas, sino <strong>agrupadas por contextos</strong>: estudiantes dentro de escuelas, personas dentro de distritos, ciudadanos dentro de países. Aquí usamos modelos <strong>multinivel o mixtos</strong>, que permiten modelar tanto los efectos individuales como los contextuales, y estimar la variabilidad entre niveles.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Ilustración_sin_título 3.png" class="img-fluid figure-img" width="471"></p>
<figcaption>No todo se ajusta a un modelo lineal</figcaption>
</figure>
</div>
</section>
<section id="modelos-lineales-generalizados" class="level3" data-number="8.4.2">
<h3 data-number="8.4.2" class="anchored" data-anchor-id="modelos-lineales-generalizados"><span class="header-section-number">8.4.2</span> Modelos lineales generalizados</h3>
<p>Puede ser que, en principio, todos estos modelos (logística, Poisson, ordinal, multinomial) pueden parecer distintas herramientas. Pero en realidad, forman parte de una misma familia: <strong>los modelos lineales generalizados</strong>, o <strong>GLM</strong> por sus siglas en inglés (<em>Generalized Linear Models</em>). Todo siguen una misma lógica: todos estos modelos parten de la misma idea básica de la regresión lineal, pero <strong>relajan o adaptan dos cosas</strong> fundamentales:</p>
<ol type="1">
<li>El tipo de <strong>distribución</strong> que tiene la variable respuesta.</li>
<li>La <strong>función</strong> que conecta esa variable respuesta con la combinación lineal de predictores.</li>
</ol>
<p>Esta estructura común tiene tres componentes clave:</p>
<ol type="1">
<li><strong>Una variable respuesta</strong> <span class="math inline">\(Y\)</span> que puede seguir distintas distribuciones: normal, binomial, Poisson, etc.</li>
<li><strong>Un predictor lineal</strong>: la parte en común <span class="math inline">\(\eta = \alpha + \beta_1 x_1 + \beta_2 x_2 + \dots\)</span></li>
<li><strong>Una función de enlace</strong> (<em>link function</em>): que conecta el valor esperado de <span class="math inline">\(Y\)</span> con el predictor lineal.</li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Tipo de regresión</th>
<th>Distribución de <span class="math inline">\(Y\)</span></th>
<th>Enlace (link)</th>
<th>Contexto común en ciencias sociales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Lineal</td>
<td>Normal</td>
<td>Identidad <span class="math inline">\(\mu = \eta\)</span></td>
<td>Predicción de ingresos, satisfacción, etc.</td>
</tr>
<tr class="even">
<td>Logística</td>
<td>Binomial</td>
<td>Logit <span class="math inline">\(\log(\mu / (1-\mu)) = \eta\)</span></td>
<td>Participación, afiliación, apoyo político</td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td>Poisson</td>
<td>Log <span class="math inline">\(\log(\mu) = \eta\)</span></td>
<td>Conteo de eventos: marchas, reuniones, crímenes</td>
</tr>
<tr class="even">
<td>Ordinal logit</td>
<td>Categórica ordinal</td>
<td>Logit acumulado</td>
<td>Opiniones, niveles de confianza o satisfacción</td>
</tr>
<tr class="odd">
<td>Multinomial logit</td>
<td>Categórica nominal</td>
<td>Multilogit</td>
<td>Preferencias electorales, elección de vivienda</td>
</tr>
</tbody>
</table>
<p>R nos permite ajustar todos estos modelos usando la misma función: <code>glm()</code>. Lo único que cambia es la <strong>familia</strong> que indicamos en el argumento <code>family =</code>.</p>
<pre><code># Regresión logística 
glm(participa ~ edad + educacion, data = encuesta, family = binomial)

# Regresión de Poisson 
glm(n_conflictos ~ pobreza + desempleo, data = regiones, family = poisson)

# Regresión lineal clásica (
glm(satisfaccion ~ ingreso + zona, data = datos, family = gaussian)</code></pre>
<p>De hecho, muchas veces, cuando el modelo lineal clásico falla (por violaciones de normalidad, varianza desigual, o variable respuesta inapropiada), el camino no es abandonar la regresión, sino <strong>moverse dentro de la familia GLM</strong> hacia un modelo más adecuado.</p>
</section>
</section>
<section id="resumen-del-capítulo" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="resumen-del-capítulo"><span class="header-section-number">8.5</span> Resumen del capítulo</h2>
<p>La regresión es una herramienta estadística que permite modelar la relación entre una variable respuesta cuantitativa y una o más variables explicativas. Su forma más básica es la regresión lineal simple, que asume una relación lineal entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, expresada como <span class="math inline">\(y = \alpha + \beta x\)</span>. Los parámetros del modelo (<span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>) se estiman mediante el método de mínimos cuadrados ordinarios (OLS), que busca minimizar la suma de los errores al cuadrado.</p>
<p>El coeficiente <span class="math inline">\(\beta\)</span> representa el cambio promedio en <span class="math inline">\(y\)</span> ante un cambio de una unidad en <span class="math inline">\(x\)</span>, mientras que <span class="math inline">\(\alpha\)</span> indica el valor esperado de <span class="math inline">\(y\)</span> cuando <span class="math inline">\(x = 0\)</span>. La calidad del ajuste se evalúa con el coeficiente de determinación <span class="math inline">\(R^2\)</span>, que mide qué proporción de la variabilidad en <span class="math inline">\(y\)</span> es explicada por el modelo. El error estándar residual (<span class="math inline">\(\sigma\)</span>) resume la dispersión de los datos en torno a la recta ajustada.</p>
<p>La inferencia sobre los coeficientes se realiza mediante pruebas <span class="math inline">\(t\)</span>, intervalos de confianza y valores p.&nbsp;Se parte de la hipótesis nula de que <span class="math inline">\(\beta = 0\)</span>, es decir, que no hay relación lineal en la población. Para interpretar correctamente estos resultados, el modelo debe cumplir con ciertos supuestos: linealidad, independencia, homocedasticidad y normalidad de los errores. Estas condiciones se verifican mediante el análisis gráfico de residuos.</p>
<p>La regresión múltiple extiende el modelo lineal para incluir varias variables explicativas. Cada coeficiente estimado representa el efecto de una variable, manteniendo constante el resto. Se introdujo el uso de VIF para evaluar colinealidad entre predictores, y el <span class="math inline">\(R^2\)</span> ajustado como medida más precisa del ajuste cuando se incluyen múltiples variables. Se explicó también cómo interpretar variables categóricas mediante codificación por referencia y cómo controlar por variables para evitar sesgos por omisión. Rcordar además a los modelos con interacción, donde el efecto de una variable puede depender del valor de otra. Estos modelos incluyen un término multiplicativo que modifica la pendiente, permitiendo estimar relaciones diferenciadas según grupos.</p>
<p>Hay una visión general de otros modelos de regresión más allá de la lineal: regresión logística para variables binarias, ordinal para escalas tipo Likert, multinomial para respuestas sin orden, Poisson para conteos, polinómica para relaciones curvas, y modelos multinivel para datos jerárquicos. Todos estos se agrupan dentro de la familia de los Modelos Lineales Generalizados (GLM), que permiten adaptar la regresión a diferentes tipos de distribución y estructura de datos. La elección del modelo debe hacerse en función del tipo de variable respuesta y de los supuestos que se puedan sostener en el análisis.</p>
</section>
<section id="ejercicios" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="ejercicios"><span class="header-section-number">8.6</span> Ejercicios</h2>
<p><strong>1.</strong> En un modelo de regresión lineal simple, ¿cuál de las siguientes afirmaciones describe correctamente el significado de la pendiente (<span class="math inline">\(\beta\)</span>)?</p>
<ol type="A">
<li>Es el valor promedio de la variable respuesta.<br>
</li>
<li>Es el valor esperado de <span class="math inline">\(y\)</span> cuando <span class="math inline">\(x = 0\)</span>.<br>
</li>
<li>Es el cambio promedio en <span class="math inline">\(y\)</span> por cada unidad adicional en <span class="math inline">\(x\)</span>.<br>
</li>
<li>Es el punto donde la recta cruza el eje <span class="math inline">\(x\)</span>.</li>
</ol>
<p><strong>2.</strong> En R, ¿cuál de estas fórmulas se utiliza para ajustar un modelo de regresión lineal múltiple? sin interación?</p>
<ol type="A">
<li><code>lm(y = x1 + x2, data = df)</code><br>
</li>
<li><code>lm(y ~ x1 + x2, data = df)</code><br>
</li>
<li><code>lm(x1 + x2 ~ y, data = df)</code><br>
</li>
<li><code>lm(y ~ x1 * x2 * x3, data = df)</code></li>
</ol>
<p><strong>3.</strong> ¿Qué significa el término <span class="math inline">\(\hat{y}_i\)</span> en un modelo de regresión?</p>
<ol type="A">
<li>Es el error cuadrático medio del modelo.<br>
</li>
<li>Es el valor observado de la variable dependiente.<br>
</li>
<li>Es el valor predicho por el modelo para la observación <span class="math inline">\(i\)</span>.<br>
</li>
<li>Es el coeficiente estimado para la variable independiente <span class="math inline">\(x_i\)</span>.</li>
</ol>
<p><strong>4.</strong> ¿Qué indica un coeficiente de determinación <span class="math inline">\(R^2\)</span> igual a 0.67?</p>
<ol type="A">
<li>El modelo es significativo en un 67% de los casos.<br>
</li>
<li>El 67% de la varianza total de <span class="math inline">\(y\)</span> es explicada por el modelo.<br>
</li>
<li>El modelo tiene un 67% de precisión para predecir nuevas observaciones.<br>
</li>
<li>El valor predicho es 0.67 veces el valor observado.</li>
</ol>
<p><strong>5.</strong> En un modelo con interacción como <code>lm(y ~ x * z)</code>, ¿qué significa el término <code>x:z</code>?</p>
<ol type="A">
<li>Es el efecto total combinado de <span class="math inline">\(x\)</span> y <span class="math inline">\(z\)</span>.<br>
</li>
<li>Es el valor promedio del modelo cuando <span class="math inline">\(x = z = 0\)</span>.<br>
</li>
<li>Representa el cambio en la pendiente de <span class="math inline">\(x\)</span> dependiendo del valor de <span class="math inline">\(z\)</span>.<br>
</li>
<li>Es el coeficiente de correlación entre <span class="math inline">\(x\)</span> y <span class="math inline">\(z\)</span>.</li>
</ol>
<p><strong>6.</strong> ¿Cuál de los siguientes supuestos es necesario para que los valores p del modelo lineal clásico sean confiables?</p>
<ol type="A">
<li>Que las variables independientes estén normalizadas.<br>
</li>
<li>Que los residuos del modelo sigan una distribución normal.<br>
</li>
<li>Que todas las variables tengan media cero.<br>
</li>
<li>Que <span class="math inline">\(R^2\)</span> sea mayor a 0.5.</li>
</ol>
<p><strong>7.</strong> ¿Qué observación es correcta sobre el uso del gráfico Residuals vs Fitted en regresión?</p>
<ol type="A">
<li>Permite verificar si los residuos tienen varianza constante.<br>
</li>
<li>Permite detectar si hay outliers que afectan el modelo.<br>
</li>
<li>Permite evaluar si la relación entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> es aproximadamente lineal.<br>
</li>
<li>Permite identificar si el modelo cumple con la distribución binomial.</li>
</ol>
<p><strong>8.</strong> ¿Qué función usamos en R para evaluar la multicolinealidad entre variables explicativas?</p>
<ol type="A">
<li><code>summary()</code><br>
</li>
<li><code>cor()</code><br>
</li>
<li><code>vif()</code><br>
</li>
<li><code>resid()</code></li>
</ol>
<p><strong>9.</strong> Si el modelo lineal simple tiene un error estándar residual (<span class="math inline">\(\sigma\)</span>) de 3.25, ¿qué interpretación es más adecuada?</p>
<ol type="A">
<li>El valor estimado del intercepto es 3.25.<br>
</li>
<li>En promedio, los valores de <span class="math inline">\(y\)</span> se desvían 3.25 unidades de la recta ajustada.<br>
</li>
<li>El valor de la pendiente tiene una significancia de 3.25.<br>
</li>
<li><span class="math inline">\(R^2\)</span> debe ser mayor a 0.325 para ser aceptable.</li>
</ol>
<p><strong>10.</strong> ¿Cuál de las siguientes afirmaciones representa mejor la lógica de “control estadístico” en regresión múltiple?</p>
<ol type="A">
<li>Es usar una regresión para seleccionar solo la variable más significativa.<br>
</li>
<li>Es estimar el efecto de una variable manteniendo constantes las demás.<br>
</li>
<li>Es aplicar transformaciones logarítmicas para mejorar el modelo.<br>
</li>
<li>Es usar solo variables independientes no correlacionadas.</li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-agresti2018" class="csl-entry" role="listitem">
Agresti, Alan. 2018. <em>Statistical methods for the social sciences</em>. Fifth edition. Boston: Pearson.
</div>
</div>
</section>

</main> <!-- /main -->
<button id="toc-toggle-btn" aria-label="Abrir contenido">Contenido ▤</button>
<script>
  (function () {
    const btn = document.getElementById('toc-toggle-btn');
    if (!btn) return;
    btn.addEventListener('click', function () {
      document.body.classList.toggle('toc-open');
    });
    // Cierra el drawer al tocar fuera del panel (móviles)
    document.addEventListener('click', function (e) {
      const panel = document.getElementById('quarto-margin-sidebar');
      if (!panel) return;
      const clickedInside = panel.contains(e.target) || btn.contains(e.target);
      if (!clickedInside && document.body.classList.contains('toc-open')) {
        document.body.classList.remove('toc-open');
      }
    });
  })();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./comp.html" class="pagination-link" aria-label="Comparando grupos">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Comparando grupos</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./glosariofunciones.html" class="pagination-link" aria-label="Glosario de funciones y operaciones útiles en R">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Glosario de funciones y operaciones útiles en R</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>